#!/usr/bin/env python3

"""
Claude Night Pilot å¿«é€Ÿæ€§èƒ½æ¸¬è©¦
æ¸¬é‡é—œéµæ€§èƒ½æŒ‡æ¨™ä¸¦èˆ‡ç›®æ¨™é€²è¡Œæ¯”è¼ƒ
"""

import subprocess
import time
import json
import statistics
import os
from pathlib import Path

class PerformanceTester:
    def __init__(self):
        self.cli_path = "./target/release/cnp-unified"
        self.results = {}
        
    def run_command_with_timing(self, cmd, iterations=5):
        """åŸ·è¡Œå‘½ä»¤ä¸¦æ¸¬é‡æ™‚é–“"""
        times = []
        for _ in range(iterations):
            start = time.time()
            try:
                result = subprocess.run(
                    cmd, 
                    shell=True, 
                    capture_output=True, 
                    text=True,
                    timeout=10
                )
                end = time.time()
                execution_time = end - start
                times.append(execution_time)
                
                # ç¬¬ä¸€æ¬¡è¿­ä»£è¨˜éŒ„è¼¸å‡ºå¤§å°
                if _ == 0:
                    output_size = len(result.stdout) + len(result.stderr)
                    return times, result.returncode == 0, output_size
                    
            except subprocess.TimeoutExpired:
                times.append(10.0)  # Timeout ä½œç‚ºæœ€å¤§å€¼
                
        return times, True, 0
    
    def test_cli_startup(self):
        """æ¸¬è©¦ CLI å•Ÿå‹•æ™‚é–“"""
        print("ğŸš€ æ¸¬è©¦ CLI å•Ÿå‹•æ€§èƒ½...")
        
        # Help å‘½ä»¤ (æœ€å¿«çš„å‘½ä»¤)
        times, success, size = self.run_command_with_timing(f"{self.cli_path} --help")
        
        self.results["cli_startup"] = {
            "command": "help",
            "avg_time": statistics.mean(times),
            "min_time": min(times),
            "max_time": max(times),
            "median_time": statistics.median(times),
            "success": success,
            "output_size": size,
            "target": 0.1,  # 100ms ç›®æ¨™
            "meets_target": statistics.median(times) < 0.1
        }
        
    def test_cli_commands(self):
        """æ¸¬è©¦å„ç¨® CLI å‘½ä»¤æ€§èƒ½"""
        print("âš¡ æ¸¬è©¦ CLI å‘½ä»¤æ€§èƒ½...")
        
        commands = [
            ("health", f"{self.cli_path} health --format json"),
            ("cooldown", f"{self.cli_path} cooldown --format json"),
        ]
        
        for cmd_name, cmd in commands:
            times, success, size = self.run_command_with_timing(cmd, iterations=3)
            
            self.results[f"cli_{cmd_name}"] = {
                "command": cmd_name,
                "avg_time": statistics.mean(times),
                "min_time": min(times),
                "max_time": max(times),
                "median_time": statistics.median(times),
                "success": success,
                "output_size": size,
                "target": 1.0,  # 1s ç›®æ¨™ (é€™äº›å‘½ä»¤è¼ƒè¤‡é›œ)
                "meets_target": statistics.median(times) < 1.0
            }
    
    def test_binary_size(self):
        """æ¸¬è©¦äºŒé€²åˆ¶æ–‡ä»¶å¤§å°"""
        print("ğŸ“¦ æª¢æŸ¥äºŒé€²åˆ¶æ–‡ä»¶å¤§å°...")
        
        if os.path.exists(self.cli_path):
            size_bytes = os.path.getsize(self.cli_path)
            size_mb = size_bytes / (1024 * 1024)
            
            self.results["binary_size"] = {
                "size_bytes": size_bytes,
                "size_mb": round(size_mb, 2),
                "target_mb": 10,
                "meets_target": size_mb < 10
            }
        else:
            print(f"âš ï¸ äºŒé€²åˆ¶æ–‡ä»¶ä¸å­˜åœ¨: {self.cli_path}")
    
    def test_cold_vs_warm_start(self):
        """æ¸¬è©¦å†·å•Ÿå‹• vs ç†±å•Ÿå‹•æ€§èƒ½"""
        print("â„ï¸ æ¸¬è©¦å†·å•Ÿå‹• vs ç†±å•Ÿå‹•...")
        
        # æ¸…ç†ç³»çµ±ç·©å­˜ (macOS)
        subprocess.run("sudo purge", shell=True, capture_output=True)
        
        # å†·å•Ÿå‹•
        cold_times, _, _ = self.run_command_with_timing(f"{self.cli_path} --help", iterations=1)
        
        # ç†±å•Ÿå‹•
        warm_times, _, _ = self.run_command_with_timing(f"{self.cli_path} --help", iterations=3)
        
        self.results["startup_comparison"] = {
            "cold_start": cold_times[0] if cold_times else 0,
            "warm_start_avg": statistics.mean(warm_times) if warm_times else 0,
            "improvement": cold_times[0] - statistics.mean(warm_times) if cold_times and warm_times else 0
        }
    
    def run_all_tests(self):
        """åŸ·è¡Œæ‰€æœ‰æ€§èƒ½æ¸¬è©¦"""
        print("ğŸ”¥ Claude Night Pilot æ€§èƒ½åŸºæº–æ¸¬è©¦")
        print("=" * 50)
        
        self.test_binary_size()
        self.test_cli_startup()
        self.test_cli_commands()
        self.test_cold_vs_warm_start()
        
        return self.results
    
    def generate_report(self):
        """ç”Ÿæˆæ€§èƒ½å ±å‘Š"""
        print("\nğŸ“Š æ€§èƒ½æ¸¬è©¦çµæœ")
        print("=" * 50)
        
        # äºŒé€²åˆ¶å¤§å°
        if "binary_size" in self.results:
            bs = self.results["binary_size"]
            status = "âœ…" if bs["meets_target"] else "âŒ"
            print(f"\nğŸ“¦ äºŒé€²åˆ¶å¤§å°")
            print(f"  {status} å¤§å°: {bs['size_mb']} MB (ç›®æ¨™: <{bs['target_mb']} MB)")
        
        # CLI æ€§èƒ½
        print(f"\nâš¡ CLI æ€§èƒ½")
        for key, result in self.results.items():
            if key.startswith("cli_"):
                status = "âœ…" if result["meets_target"] else "âŒ"
                print(f"  {status} {result['command']}: {result['median_time']:.3f}s (ç›®æ¨™: <{result['target']}s)")
                print(f"      ç¯„åœ: {result['min_time']:.3f}s - {result['max_time']:.3f}s")
        
        # å•Ÿå‹•æ¯”è¼ƒ
        if "startup_comparison" in self.results:
            sc = self.results["startup_comparison"]
            print(f"\nâ„ï¸ å•Ÿå‹•æ€§èƒ½")
            print(f"  å†·å•Ÿå‹•: {sc['cold_start']:.3f}s")
            print(f"  ç†±å•Ÿå‹•: {sc['warm_start_avg']:.3f}s")
            print(f"  æ”¹å–„: {sc['improvement']:.3f}s")
        
        # ç¸½é«”è©•ä¼°
        print(f"\nğŸ¯ ç¸½é«”è©•ä¼°")
        total_tests = 0
        passed_tests = 0
        
        for key, result in self.results.items():
            if isinstance(result, dict) and "meets_target" in result:
                total_tests += 1
                if result["meets_target"]:
                    passed_tests += 1
        
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        print(f"  é€šéç‡: {passed_tests}/{total_tests} ({success_rate:.1f}%)")
        
        if success_rate >= 80:
            print("  ğŸ‰ æ€§èƒ½å„ªç§€ï¼")
        elif success_rate >= 60:
            print("  ğŸ‘ æ€§èƒ½è‰¯å¥½ï¼Œæœ‰æ”¹å–„ç©ºé–“")
        else:
            print("  âš ï¸ éœ€è¦æ€§èƒ½å„ªåŒ–")
    
    def save_results(self, filename="performance_results.json"):
        """ä¿å­˜è©³ç´°çµæœåˆ° JSON æ–‡ä»¶"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ è©³ç´°çµæœå·²ä¿å­˜åˆ°: {filename}")

def main():
    tester = PerformanceTester()
    
    # æª¢æŸ¥äºŒé€²åˆ¶æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(tester.cli_path):
        print(f"âŒ æ‰¾ä¸åˆ° CLI äºŒé€²åˆ¶æ–‡ä»¶: {tester.cli_path}")
        print("è«‹å…ˆé‹è¡Œ: cargo build --release --bin cnp-unified")
        return
    
    # åŸ·è¡Œæ¸¬è©¦
    results = tester.run_all_tests()
    
    # ç”Ÿæˆå ±å‘Š
    tester.generate_report()
    
    # ä¿å­˜çµæœ
    tester.save_results()

if __name__ == "__main__":
    main()