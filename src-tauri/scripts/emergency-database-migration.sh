#!/bin/bash
# ğŸš¨ Claude Night Pilot - ç·Šæ€¥è³‡æ–™åº«è·¯å¾‘çµ±ä¸€è…³æœ¬
# åŸºæ–¼ SCHEDULER_IMPLEMENTATION_ROADMAP.md Day 1 P0 ä»»å‹™
# å‰µå»ºæ™‚é–“: 2025-08-17T17:45:00+00:00

set -euo pipefail

# é¡è‰²å®šç¾©
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥èªŒå‡½æ•¸
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# é…ç½®è®Šæ•¸
LEGACY_DB="claude-pilot.db"
UNIFIED_DB="claude-night-pilot.db"
BACKUP_DIR="./backups/$(date +%Y%m%d_%H%M%S)"
MIGRATION_LOG="$BACKUP_DIR/migration.log"

# æª¢æŸ¥ä¾è³´
check_dependencies() {
    log_info "æª¢æŸ¥ç³»çµ±ä¾è³´..."
    
    if ! command -v sqlite3 &> /dev/null; then
        log_error "sqlite3 æœªå®‰è£ï¼Œè«‹å…ˆå®‰è£ SQLite"
        exit 1
    fi
    
    if ! command -v rsync &> /dev/null; then
        log_error "rsync æœªå®‰è£ï¼Œè«‹å…ˆå®‰è£ rsync"
        exit 1
    fi
    
    log_success "ä¾è³´æª¢æŸ¥å®Œæˆ"
}

# å‰µå»ºå‚™ä»½ç›®éŒ„
create_backup_directory() {
    log_info "å‰µå»ºå‚™ä»½ç›®éŒ„: $BACKUP_DIR"
    mkdir -p "$BACKUP_DIR"
    echo "Migration started at $(date)" > "$MIGRATION_LOG"
}

# å‚™ä»½ç¾æœ‰è³‡æ–™åº«
backup_existing_databases() {
    log_info "å‚™ä»½ç¾æœ‰è³‡æ–™åº«..."
    
    # å‚™ä»½èˆŠè³‡æ–™åº«
    if [[ -f "$LEGACY_DB" ]]; then
        log_info "å‚™ä»½èˆŠè³‡æ–™åº«: $LEGACY_DB"
        cp "$LEGACY_DB" "$BACKUP_DIR/claude-pilot-backup.db"
        log_success "èˆŠè³‡æ–™åº«å‚™ä»½å®Œæˆ"
        echo "Legacy database backed up: $LEGACY_DB -> $BACKUP_DIR/claude-pilot-backup.db" >> "$MIGRATION_LOG"
    else
        log_warning "èˆŠè³‡æ–™åº«æª”æ¡ˆä¸å­˜åœ¨: $LEGACY_DB"
        echo "Legacy database not found: $LEGACY_DB" >> "$MIGRATION_LOG"
    fi
    
    # å‚™ä»½çµ±ä¸€è³‡æ–™åº«ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if [[ -f "$UNIFIED_DB" ]]; then
        log_info "å‚™ä»½çµ±ä¸€è³‡æ–™åº«: $UNIFIED_DB"
        cp "$UNIFIED_DB" "$BACKUP_DIR/claude-night-pilot-backup.db"
        log_success "çµ±ä¸€è³‡æ–™åº«å‚™ä»½å®Œæˆ"
        echo "Unified database backed up: $UNIFIED_DB -> $BACKUP_DIR/claude-night-pilot-backup.db" >> "$MIGRATION_LOG"
    else
        log_info "çµ±ä¸€è³‡æ–™åº«æª”æ¡ˆä¸å­˜åœ¨: $UNIFIED_DB (é€™æ˜¯æ­£å¸¸çš„)"
        echo "Unified database not found: $UNIFIED_DB (this is normal)" >> "$MIGRATION_LOG"
    fi
}

# æª¢æŸ¥è³‡æ–™åº«çµæ§‹
check_database_schema() {
    local db_file="$1"
    local db_name="$2"
    
    log_info "æª¢æŸ¥ $db_name è³‡æ–™åº«çµæ§‹..."
    
    if [[ ! -f "$db_file" ]]; then
        log_warning "$db_name è³‡æ–™åº«ä¸å­˜åœ¨: $db_file"
        return 1
    fi
    
    # æª¢æŸ¥è¡¨çµæ§‹
    local tables=$(sqlite3 "$db_file" ".tables")
    log_info "$db_name åŒ…å«çš„è¡¨: $tables"
    echo "$db_name tables: $tables" >> "$MIGRATION_LOG"
    
    # æª¢æŸ¥ prompts è¡¨
    if sqlite3 "$db_file" ".schema prompts" &>/dev/null; then
        local prompt_count=$(sqlite3 "$db_file" "SELECT COUNT(*) FROM prompts;")
        log_info "$db_name prompts è¡¨è¨˜éŒ„æ•¸: $prompt_count"
        echo "$db_name prompts count: $prompt_count" >> "$MIGRATION_LOG"
    fi
    
    # æª¢æŸ¥ jobs è¡¨
    if sqlite3 "$db_file" ".schema jobs" &>/dev/null; then
        local job_count=$(sqlite3 "$db_file" "SELECT COUNT(*) FROM jobs;")
        log_info "$db_name jobs è¡¨è¨˜éŒ„æ•¸: $job_count"
        echo "$db_name jobs count: $job_count" >> "$MIGRATION_LOG"
    fi
    
    # æª¢æŸ¥ schedules è¡¨ï¼ˆèˆŠç‰ˆæœ¬ï¼‰
    if sqlite3 "$db_file" ".schema schedules" &>/dev/null; then
        local schedule_count=$(sqlite3 "$db_file" "SELECT COUNT(*) FROM schedules;")
        log_info "$db_name schedules è¡¨è¨˜éŒ„æ•¸: $schedule_count"
        echo "$db_name schedules count: $schedule_count" >> "$MIGRATION_LOG"
    fi
    
    return 0
}

# å‰µå»ºçµ±ä¸€è³‡æ–™åº«çµæ§‹
create_unified_database() {
    log_info "å‰µå»ºçµ±ä¸€è³‡æ–™åº«çµæ§‹..."
    
    # å¦‚æœçµ±ä¸€è³‡æ–™åº«å·²å­˜åœ¨ï¼Œå…ˆå‚™ä»½
    if [[ -f "$UNIFIED_DB" ]]; then
        log_warning "çµ±ä¸€è³‡æ–™åº«å·²å­˜åœ¨ï¼Œå°‡è¦†è“‹ç¾æœ‰æª”æ¡ˆ"
    fi
    
    # å‰µå»ºæ–°çš„çµ±ä¸€è³‡æ–™åº«
    cat > "$BACKUP_DIR/unified_schema.sql" << 'EOF'
-- Claude Night Pilot çµ±ä¸€è³‡æ–™åº«çµæ§‹
-- åŸºæ–¼ SCHEDULER_COMPREHENSIVE_REFACTORING_PLAN.md

-- å•Ÿç”¨å¤–éµç´„æŸ
PRAGMA foreign_keys = ON;

-- Prompts è¡¨ (ä¿æŒç¾æœ‰çµæ§‹)
CREATE TABLE IF NOT EXISTS prompts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT NOT NULL,
    content TEXT NOT NULL,
    tags TEXT,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- çµ±ä¸€ Jobs è¡¨ (æ•´åˆæ‰€æœ‰ç¾æœ‰åŠŸèƒ½)
CREATE TABLE IF NOT EXISTS unified_jobs (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    prompt_id TEXT NOT NULL,
    cron_expression TEXT NOT NULL,
    status TEXT NOT NULL DEFAULT 'active',
    job_type TEXT NOT NULL DEFAULT 'scheduled',
    priority INTEGER DEFAULT 5,
    
    -- ä¼æ¥­ç´šåŠŸèƒ½
    execution_count INTEGER DEFAULT 0,
    failure_count INTEGER DEFAULT 0,
    last_run_time TEXT,
    next_run_time TEXT,
    
    -- vibe-kanban æ¨¡å¼
    parent_job_id TEXT,
    
    -- åŸ·è¡Œé¸é … (JSON)
    execution_options TEXT DEFAULT '{}',
    retry_config TEXT DEFAULT '{}',
    notification_config TEXT,
    
    -- æ¨™ç±¤èˆ‡å…ƒæ•¸æ“š
    tags TEXT DEFAULT '[]',
    metadata TEXT DEFAULT '{}',
    
    -- æ™‚é–“æˆ³
    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    created_by TEXT,
    
    FOREIGN KEY (parent_job_id) REFERENCES unified_jobs(id) ON DELETE CASCADE
);

-- ä»»å‹™åŸ·è¡Œæµç¨‹è¡¨ (åŸºæ–¼ vibe-kanban ExecutionProcess)
CREATE TABLE IF NOT EXISTS job_execution_processes (
    id TEXT PRIMARY KEY,
    job_id TEXT NOT NULL,
    process_type TEXT NOT NULL CHECK (process_type IN ('setup', 'execution', 'cleanup', 'validation')),
    status TEXT NOT NULL CHECK (status IN ('queued', 'running', 'completed', 'failed', 'cancelled', 'retrying')),
    start_time TEXT NOT NULL,
    end_time TEXT,
    output TEXT,
    error_message TEXT,
    retry_count INTEGER DEFAULT 0,
    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (job_id) REFERENCES unified_jobs(id) ON DELETE CASCADE
);

-- ä»»å‹™åŸ·è¡Œçµæœè¡¨ (ä¾†è‡ª RealTimeExecutor)
CREATE TABLE IF NOT EXISTS job_execution_results (
    id TEXT PRIMARY KEY,
    job_id TEXT NOT NULL,
    prompt_id TEXT NOT NULL,
    status TEXT NOT NULL,
    start_time TEXT NOT NULL,
    end_time TEXT NOT NULL,
    duration_ms INTEGER NOT NULL,
    output TEXT,
    error_message TEXT,
    retry_count INTEGER DEFAULT 0,
    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (job_id) REFERENCES unified_jobs(id) ON DELETE CASCADE
);

-- ä½¿ç”¨é‡è¿½è¹¤è¡¨ (åŸºæ–¼ ccusage æ¨¡å¼)
CREATE TABLE IF NOT EXISTS usage_tracking (
    id TEXT PRIMARY KEY,
    job_id TEXT,
    session_id TEXT,
    tokens_input INTEGER DEFAULT 0,
    tokens_output INTEGER DEFAULT 0,
    tokens_total INTEGER DEFAULT 0,
    cost_usd REAL DEFAULT 0.0,
    model_name TEXT,
    execution_duration_ms INTEGER DEFAULT 0,
    timestamp TEXT NOT NULL,
    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (job_id) REFERENCES unified_jobs(id) ON DELETE SET NULL
);

-- ç³»çµ±é…ç½®è¡¨
CREATE TABLE IF NOT EXISTS system_config (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL,
    description TEXT,
    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- ç´¢å¼•å„ªåŒ–
CREATE INDEX IF NOT EXISTS idx_unified_jobs_status ON unified_jobs(status);
CREATE INDEX IF NOT EXISTS idx_unified_jobs_created_at ON unified_jobs(created_at);
CREATE INDEX IF NOT EXISTS idx_unified_jobs_parent ON unified_jobs(parent_job_id);
CREATE INDEX IF NOT EXISTS idx_execution_processes_job_id ON job_execution_processes(job_id);
CREATE INDEX IF NOT EXISTS idx_execution_processes_status ON job_execution_processes(status);
CREATE INDEX IF NOT EXISTS idx_execution_results_job_id ON job_execution_results(job_id);
CREATE INDEX IF NOT EXISTS idx_usage_tracking_job_id ON usage_tracking(job_id);
CREATE INDEX IF NOT EXISTS idx_usage_tracking_timestamp ON usage_tracking(timestamp);

-- æ’å…¥ç³»çµ±é…ç½®
INSERT OR REPLACE INTO system_config (key, value, description) VALUES
('database_version', '2.0.0-unified', 'Unified database schema version'),
('migration_date', datetime('now'), 'Date when migration was completed'),
('scheduler_type', 'unified', 'Type of scheduler implementation');
EOF

    # æ‡‰ç”¨è³‡æ–™åº«çµæ§‹
    log_info "æ‡‰ç”¨çµ±ä¸€è³‡æ–™åº«çµæ§‹åˆ° $UNIFIED_DB"
    sqlite3 "$UNIFIED_DB" < "$BACKUP_DIR/unified_schema.sql"
    log_success "çµ±ä¸€è³‡æ–™åº«çµæ§‹å‰µå»ºå®Œæˆ"
}

# é·ç§»èˆŠè³‡æ–™åº«è³‡æ–™
migrate_legacy_data() {
    if [[ ! -f "$LEGACY_DB" ]]; then
        log_info "èˆŠè³‡æ–™åº«ä¸å­˜åœ¨ï¼Œè·³éè³‡æ–™é·ç§»"
        return 0
    fi
    
    log_info "é–‹å§‹é·ç§»èˆŠè³‡æ–™åº«è³‡æ–™..."
    
    # é·ç§» prompts è¡¨
    if sqlite3 "$LEGACY_DB" ".schema prompts" &>/dev/null; then
        log_info "é·ç§» prompts è¡¨..."
        sqlite3 "$LEGACY_DB" ".output '$BACKUP_DIR/prompts_export.sql'" ".dump prompts"
        sqlite3 "$UNIFIED_DB" < "$BACKUP_DIR/prompts_export.sql" 2>/dev/null || true
        log_success "prompts è¡¨é·ç§»å®Œæˆ"
    fi
    
    # é·ç§» jobs è¡¨åˆ° unified_jobs
    if sqlite3 "$LEGACY_DB" ".schema jobs" &>/dev/null; then
        log_info "é·ç§» jobs è¡¨åˆ° unified_jobs..."
        
        # å°å‡º jobs è³‡æ–™ä¸¦è½‰æ›æ ¼å¼
        sqlite3 -header -csv "$LEGACY_DB" "SELECT * FROM jobs;" > "$BACKUP_DIR/jobs_export.csv"
        
        # å‰µå»ºè½‰æ›è…³æœ¬
        cat > "$BACKUP_DIR/convert_jobs.py" << 'EOF'
import csv
import sqlite3
import sys
import json
from datetime import datetime

def convert_jobs(legacy_csv, unified_db):
    conn = sqlite3.connect(unified_db)
    cursor = conn.cursor()
    
    with open(legacy_csv, 'r', encoding='utf-8') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            # è½‰æ›è³‡æ–™æ ¼å¼
            cursor.execute("""
                INSERT OR REPLACE INTO unified_jobs 
                (id, name, prompt_id, cron_expression, status, job_type, 
                 execution_count, failure_count, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                row.get('id', ''),
                row.get('name', ''),
                row.get('prompt_id', ''),
                row.get('cron_expression', ''),
                row.get('status', 'active'),
                row.get('job_type', 'scheduled'),
                int(row.get('execution_count', 0) or 0),
                int(row.get('failure_count', 0) or 0),
                row.get('created_at', datetime.now().isoformat()),
                row.get('updated_at', datetime.now().isoformat())
            ))
    
    conn.commit()
    conn.close()
    print(f"Converted jobs from {legacy_csv} to {unified_db}")

if __name__ == "__main__":
    convert_jobs(sys.argv[1], sys.argv[2])
EOF
        
        # åŸ·è¡Œè½‰æ›
        if command -v python3 &> /dev/null; then
            python3 "$BACKUP_DIR/convert_jobs.py" "$BACKUP_DIR/jobs_export.csv" "$UNIFIED_DB"
            log_success "jobs è¡¨é·ç§»å®Œæˆ"
        else
            log_warning "Python3 æœªå®‰è£ï¼Œè·³é jobs è¡¨è‡ªå‹•è½‰æ›"
        fi
    fi
    
    # é·ç§» schedules è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if sqlite3 "$LEGACY_DB" ".schema schedules" &>/dev/null; then
        log_info "æª¢æ¸¬åˆ° schedules è¡¨ï¼Œéœ€è¦æ‰‹å‹•åˆä½µåˆ° unified_jobs"
        sqlite3 -header -csv "$LEGACY_DB" "SELECT * FROM schedules;" > "$BACKUP_DIR/schedules_export.csv"
        log_warning "schedules è¡¨å·²å°å‡ºåˆ° $BACKUP_DIR/schedules_export.csvï¼Œéœ€è¦æ‰‹å‹•æª¢æŸ¥å’Œåˆä½µ"
    fi
}

# é©—è­‰é·ç§»çµæœ
verify_migration() {
    log_info "é©—è­‰é·ç§»çµæœ..."
    
    # æª¢æŸ¥çµ±ä¸€è³‡æ–™åº«çµæ§‹
    check_database_schema "$UNIFIED_DB" "çµ±ä¸€è³‡æ–™åº«"
    
    # æ¯”è¼ƒè¨˜éŒ„æ•¸é‡
    if [[ -f "$LEGACY_DB" ]]; then
        log_info "æ¯”è¼ƒé·ç§»å‰å¾Œè³‡æ–™æ•¸é‡..."
        
        # æ¯”è¼ƒ prompts è¡¨
        if sqlite3 "$LEGACY_DB" ".schema prompts" &>/dev/null && sqlite3 "$UNIFIED_DB" ".schema prompts" &>/dev/null; then
            local legacy_prompts=$(sqlite3 "$LEGACY_DB" "SELECT COUNT(*) FROM prompts;")
            local unified_prompts=$(sqlite3 "$UNIFIED_DB" "SELECT COUNT(*) FROM prompts;")
            
            if [[ "$legacy_prompts" -eq "$unified_prompts" ]]; then
                log_success "prompts è¡¨é·ç§»é©—è­‰é€šé: $legacy_prompts = $unified_prompts"
            else
                log_warning "prompts è¡¨æ•¸é‡ä¸ä¸€è‡´: èˆŠ=$legacy_prompts, æ–°=$unified_prompts"
            fi
        fi
        
        # æª¢æŸ¥ unified_jobs è¡¨
        local unified_jobs=$(sqlite3 "$UNIFIED_DB" "SELECT COUNT(*) FROM unified_jobs;" 2>/dev/null || echo "0")
        log_info "unified_jobs è¡¨è¨˜éŒ„æ•¸: $unified_jobs"
    fi
    
    # æª¢æŸ¥è³‡æ–™åº«å®Œæ•´æ€§
    local integrity_check=$(sqlite3 "$UNIFIED_DB" "PRAGMA integrity_check;")
    if [[ "$integrity_check" == "ok" ]]; then
        log_success "è³‡æ–™åº«å®Œæ•´æ€§æª¢æŸ¥é€šé"
    else
        log_error "è³‡æ–™åº«å®Œæ•´æ€§æª¢æŸ¥å¤±æ•—: $integrity_check"
        return 1
    fi
}

# æ›´æ–°æ‡‰ç”¨é…ç½®
update_application_config() {
    log_info "æ›´æ–°æ‡‰ç”¨é…ç½®..."
    
    # å‰µå»ºé…ç½®æ›´æ–°è…³æœ¬
    cat > "$BACKUP_DIR/update_config.md" << EOF
# æ‡‰ç”¨é…ç½®æ›´æ–°æŒ‡å—

## éœ€è¦æ›´æ–°çš„æª”æ¡ˆ

1. **src-tauri/src/database_manager.rs**
   - å°‡æ‰€æœ‰ \`claude-pilot.db\` æ”¹ç‚º \`claude-night-pilot.db\`
   - æ›´æ–°è¡¨åç¨±å¾ \`jobs\` åˆ° \`unified_jobs\`

2. **src-tauri/src/scheduler/real_time_executor.rs**
   - ç¢ºèªä½¿ç”¨ \`claude-night-pilot.db\`
   - æ›´æ–°è¡¨çµæ§‹å°æ‡‰æ–°çš„ unified_jobs

3. **src-tauri/src/services/job_service.rs**
   - æ›´æ–°æŸ¥è©¢èªå¥ä½¿ç”¨ unified_jobs è¡¨
   - é©é…æ–°çš„è³‡æ–™çµæ§‹

4. **æ¸¬è©¦æª”æ¡ˆ**
   - æ›´æ–°æ‰€æœ‰æ¸¬è©¦ä¸­çš„è³‡æ–™åº«è·¯å¾‘
   - ä¿®æ”¹æ¸¬è©¦è³‡æ–™çµæ§‹å°æ‡‰æ–°è¡¨

## é©—è­‰æ­¥é©Ÿ

1. åŸ·è¡Œæ¸¬è©¦å¥—ä»¶ç¢ºä¿åŠŸèƒ½æ­£å¸¸
2. æª¢æŸ¥æ—¥èªŒä¸­æ˜¯å¦æœ‰è³‡æ–™åº«è·¯å¾‘éŒ¯èª¤
3. é©—è­‰æ’ç¨‹å™¨åŠŸèƒ½æ˜¯å¦æ­£å¸¸é‹ä½œ

## å›æ»¾æŒ‡å—

å¦‚æœé·ç§»å‡ºç¾å•é¡Œï¼Œå¯ä»¥å¾å‚™ä»½æ¢å¾©ï¼š
\`\`\`bash
cp $BACKUP_DIR/claude-pilot-backup.db claude-pilot.db
cp $BACKUP_DIR/claude-night-pilot-backup.db claude-night-pilot.db
\`\`\`
EOF
    
    log_success "é…ç½®æ›´æ–°æŒ‡å—å·²å‰µå»º: $BACKUP_DIR/update_config.md"
}

# æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
cleanup_temporary_files() {
    log_info "æ¸…ç†è‡¨æ™‚æª”æ¡ˆ..."
    
    # ä¿ç•™é‡è¦çš„å‚™ä»½å’Œæ—¥èªŒï¼Œæ¸…ç†å…¶ä»–è‡¨æ™‚æª”æ¡ˆ
    rm -f "$BACKUP_DIR/convert_jobs.py" 2>/dev/null || true
    rm -f "$BACKUP_DIR/prompts_export.sql" 2>/dev/null || true
    
    log_success "è‡¨æ™‚æª”æ¡ˆæ¸…ç†å®Œæˆ"
}

# ç”Ÿæˆé·ç§»å ±å‘Š
generate_migration_report() {
    log_info "ç”Ÿæˆé·ç§»å ±å‘Š..."
    
    cat > "$BACKUP_DIR/migration_report.md" << EOF
# Claude Night Pilot è³‡æ–™åº«é·ç§»å ±å‘Š

**é·ç§»æ™‚é–“**: $(date)
**é·ç§»ç‰ˆæœ¬**: å¾åˆ†æ•£å¼è³‡æ–™åº«åˆ°çµ±ä¸€è³‡æ–™åº« v2.0.0
**å‚™ä»½ä½ç½®**: $BACKUP_DIR

## é·ç§»æ‘˜è¦

### æª”æ¡ˆè®Šæ›´
- **èˆŠè³‡æ–™åº«**: $LEGACY_DB $(if [[ -f "$LEGACY_DB" ]]; then echo "âœ… å·²å‚™ä»½"; else echo "âŒ ä¸å­˜åœ¨"; fi)
- **çµ±ä¸€è³‡æ–™åº«**: $UNIFIED_DB âœ… å·²å‰µå»º

### è³‡æ–™é·ç§»ç‹€æ…‹
$(if [[ -f "$LEGACY_DB" ]]; then
    echo "- Prompts è¡¨: $(sqlite3 "$LEGACY_DB" "SELECT COUNT(*) FROM prompts;" 2>/dev/null || echo "0") ç­†è¨˜éŒ„å·²é·ç§»"
    if sqlite3 "$LEGACY_DB" ".schema jobs" &>/dev/null; then
        echo "- Jobs è¡¨: $(sqlite3 "$LEGACY_DB" "SELECT COUNT(*) FROM jobs;" 2>/dev/null || echo "0") ç­†è¨˜éŒ„å·²è½‰æ›ç‚º unified_jobs"
    fi
    if sqlite3 "$LEGACY_DB" ".schema schedules" &>/dev/null; then
        echo "- Schedules è¡¨: $(sqlite3 "$LEGACY_DB" "SELECT COUNT(*) FROM schedules;" 2>/dev/null || echo "0") ç­†è¨˜éŒ„éœ€è¦æ‰‹å‹•æª¢æŸ¥"
    fi
else
    echo "- èˆŠè³‡æ–™åº«ä¸å­˜åœ¨ï¼Œå»ºç«‹å…¨æ–°çµ±ä¸€è³‡æ–™åº«"
fi)

### æ–°è³‡æ–™åº«çµæ§‹
- unified_jobs: çµ±ä¸€ä»»å‹™è¡¨
- job_execution_processes: åŸ·è¡Œæµç¨‹è¿½è¹¤
- job_execution_results: åŸ·è¡Œçµæœè¨˜éŒ„
- usage_tracking: ä½¿ç”¨é‡è¿½è¹¤
- system_config: ç³»çµ±é…ç½®

## å¾ŒçºŒè¡Œå‹•é …ç›®

1. **ç«‹å³è¡Œå‹•**
   - [ ] æ›´æ–°æ‡‰ç”¨ç¨‹å¼ç¢¼ä¸­çš„è³‡æ–™åº«è·¯å¾‘
   - [ ] ä¿®æ”¹è¡¨åç¨±å¾ jobs åˆ° unified_jobs
   - [ ] åŸ·è¡Œå®Œæ•´æ¸¬è©¦å¥—ä»¶

2. **é©—è­‰æ¸¬è©¦**
   - [ ] æ’ç¨‹å™¨åŠŸèƒ½æ¸¬è©¦
   - [ ] è³‡æ–™å®Œæ•´æ€§æ¸¬è©¦
   - [ ] æ€§èƒ½åŸºæº–æ¸¬è©¦

3. **æ¸…ç†å·¥ä½œ**
   - [ ] ç¢ºèªæ–°ç³»çµ±ç©©å®šå¾Œï¼Œå¯ä»¥åˆªé™¤èˆŠè³‡æ–™åº«æª”æ¡ˆ
   - [ ] æ›´æ–°æ–‡æª”å’Œéƒ¨ç½²è…³æœ¬

## å›æ»¾è¨ˆåŠƒ

å¦‚æœéœ€è¦å›æ»¾åˆ°èˆŠç‰ˆæœ¬ï¼š
\`\`\`bash
cd $(pwd)
cp $BACKUP_DIR/claude-pilot-backup.db claude-pilot.db
rm claude-night-pilot.db
git checkout HEAD~1  # å›åˆ°é·ç§»å‰çš„ç¨‹å¼ç¢¼ç‰ˆæœ¬
\`\`\`

## æ”¯æ´è³‡æº

- å‚™ä»½æª”æ¡ˆ: $BACKUP_DIR/
- é·ç§»æ—¥èªŒ: $MIGRATION_LOG
- é…ç½®æŒ‡å—: $BACKUP_DIR/update_config.md
- å•é¡Œå›å ±: è«‹æª¢æŸ¥é·ç§»æ—¥èªŒæª”æ¡ˆ

---
**ç‹€æ…‹**: âœ… é·ç§»å®Œæˆ
**ä¸‹ä¸€æ­¥**: è«‹æŒ‰ç…§é…ç½®æ›´æ–°æŒ‡å—ä¿®æ”¹æ‡‰ç”¨ç¨‹å¼ç¢¼
EOF

    log_success "é·ç§»å ±å‘Šå·²ç”Ÿæˆ: $BACKUP_DIR/migration_report.md"
}

# ä¸»åŸ·è¡Œå‡½æ•¸
main() {
    echo "ğŸš¨ Claude Night Pilot - ç·Šæ€¥è³‡æ–™åº«è·¯å¾‘çµ±ä¸€å·¥å…·"
    echo "=================================================="
    echo ""
    
    # åŸ·è¡Œé·ç§»æ­¥é©Ÿ
    check_dependencies
    create_backup_directory
    backup_existing_databases
    check_database_schema "$LEGACY_DB" "èˆŠè³‡æ–™åº«" || true
    check_database_schema "$UNIFIED_DB" "çµ±ä¸€è³‡æ–™åº«" || true
    create_unified_database
    migrate_legacy_data
    verify_migration
    update_application_config
    cleanup_temporary_files
    generate_migration_report
    
    echo ""
    echo "ğŸ‰ è³‡æ–™åº«é·ç§»å®Œæˆï¼"
    echo ""
    echo "ğŸ“‹ ä¸‹ä¸€æ­¥è¡Œå‹•ï¼š"
    echo "1. æª¢æŸ¥é·ç§»å ±å‘Š: $BACKUP_DIR/migration_report.md"
    echo "2. é–±è®€é…ç½®æŒ‡å—: $BACKUP_DIR/update_config.md"
    echo "3. æ›´æ–°æ‡‰ç”¨ç¨‹å¼ç¢¼ä¸­çš„è³‡æ–™åº«è·¯å¾‘"
    echo "4. åŸ·è¡Œæ¸¬è©¦å¥—ä»¶é©—è­‰åŠŸèƒ½æ­£å¸¸"
    echo ""
    echo "ğŸ”’ å‚™ä»½ä½ç½®: $BACKUP_DIR"
    echo "ğŸ“ é·ç§»æ—¥èªŒ: $MIGRATION_LOG"
    echo ""
    echo "âš ï¸  é‡è¦æé†’ï¼šè«‹åœ¨ç¢ºèªæ–°ç³»çµ±ç©©å®šå¾Œå†åˆªé™¤å‚™ä»½æª”æ¡ˆ"
}

# åŸ·è¡Œä¸»å‡½æ•¸
main "$@"