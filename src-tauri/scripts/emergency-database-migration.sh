#!/bin/bash
# üö® Claude Night Pilot - Á∑äÊÄ•Ë≥áÊñôÂ∫´Ë∑ØÂæëÁµ±‰∏ÄËÖ≥Êú¨
# Âü∫Êñº SCHEDULER_IMPLEMENTATION_ROADMAP.md Day 1 P0 ‰ªªÂãô
# ÂâµÂª∫ÊôÇÈñì: 2025-08-17T17:45:00+00:00

set -euo pipefail

# È°èËâ≤ÂÆöÁæ©
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Êó•Ë™åÂáΩÊï∏
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# ÈÖçÁΩÆËÆäÊï∏
LEGACY_DB="claude-pilot.db"
UNIFIED_DB="claude-night-pilot.db"
BACKUP_DIR="./backups/$(date +%Y%m%d_%H%M%S)"
MIGRATION_LOG="$BACKUP_DIR/migration.log"

# Ê™¢Êü•‰æùË≥¥
check_dependencies() {
    log_info "Ê™¢Êü•Á≥ªÁµ±‰æùË≥¥..."
    
    if ! command -v sqlite3 &> /dev/null; then
        log_error "sqlite3 Êú™ÂÆâË£ùÔºåË´ãÂÖàÂÆâË£ù SQLite"
        exit 1
    fi
    
    if ! command -v rsync &> /dev/null; then
        log_error "rsync Êú™ÂÆâË£ùÔºåË´ãÂÖàÂÆâË£ù rsync"
        exit 1
    fi
    
    log_success "‰æùË≥¥Ê™¢Êü•ÂÆåÊàê"
}

# ÂâµÂª∫ÂÇô‰ªΩÁõÆÈåÑ
create_backup_directory() {
    log_info "ÂâµÂª∫ÂÇô‰ªΩÁõÆÈåÑ: $BACKUP_DIR"
    mkdir -p "$BACKUP_DIR"
    echo "Migration started at $(date)" > "$MIGRATION_LOG"
}

# ÂÇô‰ªΩÁèæÊúâË≥áÊñôÂ∫´
backup_existing_databases() {
    log_info "ÂÇô‰ªΩÁèæÊúâË≥áÊñôÂ∫´..."
    
    # ÂÇô‰ªΩËàäË≥áÊñôÂ∫´
    if [[ -f "$LEGACY_DB" ]]; then
        log_info "ÂÇô‰ªΩËàäË≥áÊñôÂ∫´: $LEGACY_DB"
        cp "$LEGACY_DB" "$BACKUP_DIR/claude-pilot-backup.db"
        log_success "ËàäË≥áÊñôÂ∫´ÂÇô‰ªΩÂÆåÊàê"
        echo "Legacy database backed up: $LEGACY_DB -> $BACKUP_DIR/claude-pilot-backup.db" >> "$MIGRATION_LOG"
    else
        log_warning "ËàäË≥áÊñôÂ∫´Ê™îÊ°à‰∏çÂ≠òÂú®: $LEGACY_DB"
        echo "Legacy database not found: $LEGACY_DB" >> "$MIGRATION_LOG"
    fi
    
    # ÂÇô‰ªΩÁµ±‰∏ÄË≥áÊñôÂ∫´ÔºàÂ¶ÇÊûúÂ≠òÂú®Ôºâ
    if [[ -f "$UNIFIED_DB" ]]; then
        log_info "ÂÇô‰ªΩÁµ±‰∏ÄË≥áÊñôÂ∫´: $UNIFIED_DB"
        cp "$UNIFIED_DB" "$BACKUP_DIR/claude-night-pilot-backup.db"
        log_success "Áµ±‰∏ÄË≥áÊñôÂ∫´ÂÇô‰ªΩÂÆåÊàê"
        echo "Unified database backed up: $UNIFIED_DB -> $BACKUP_DIR/claude-night-pilot-backup.db" >> "$MIGRATION_LOG"
    else
        log_info "Áµ±‰∏ÄË≥áÊñôÂ∫´Ê™îÊ°à‰∏çÂ≠òÂú®: $UNIFIED_DB (ÈÄôÊòØÊ≠£Â∏∏ÁöÑ)"
        echo "Unified database not found: $UNIFIED_DB (this is normal)" >> "$MIGRATION_LOG"
    fi
}

# Ê™¢Êü•Ë≥áÊñôÂ∫´ÁµêÊßã
check_database_schema() {
    local db_file="$1"
    local db_name="$2"
    
    log_info "Ê™¢Êü• $db_name Ë≥áÊñôÂ∫´ÁµêÊßã..."
    
    if [[ ! -f "$db_file" ]]; then
        log_warning "$db_name Ë≥áÊñôÂ∫´‰∏çÂ≠òÂú®: $db_file"
        return 1
    fi
    
    # Ê™¢Êü•Ë°®ÁµêÊßã
    local tables=$(sqlite3 "$db_file" ".tables")
    log_info "$db_name ÂåÖÂê´ÁöÑË°®: $tables"
    echo "$db_name tables: $tables" >> "$MIGRATION_LOG"
    
    # Ê™¢Êü• prompts Ë°®
    if sqlite3 "$db_file" ".schema prompts" &>/dev/null; then
        local prompt_count=$(sqlite3 "$db_file" "SELECT COUNT(*) FROM prompts;")
        log_info "$db_name prompts Ë°®Ë®òÈåÑÊï∏: $prompt_count"
        echo "$db_name prompts count: $prompt_count" >> "$MIGRATION_LOG"
    fi
    
    # Ê™¢Êü• jobs Ë°®
    if sqlite3 "$db_file" ".schema jobs" &>/dev/null; then
        local job_count=$(sqlite3 "$db_file" "SELECT COUNT(*) FROM jobs;")
        log_info "$db_name jobs Ë°®Ë®òÈåÑÊï∏: $job_count"
        echo "$db_name jobs count: $job_count" >> "$MIGRATION_LOG"
    fi
    
    # Ê™¢Êü• schedules Ë°®ÔºàËàäÁâàÊú¨Ôºâ
    if sqlite3 "$db_file" ".schema schedules" &>/dev/null; then
        local schedule_count=$(sqlite3 "$db_file" "SELECT COUNT(*) FROM schedules;")
        log_info "$db_name schedules Ë°®Ë®òÈåÑÊï∏: $schedule_count"
        echo "$db_name schedules count: $schedule_count" >> "$MIGRATION_LOG"
    fi
    
    return 0
}

# ÂâµÂª∫Áµ±‰∏ÄË≥áÊñôÂ∫´ÁµêÊßã
create_unified_database() {
    log_info "ÂâµÂª∫Áµ±‰∏ÄË≥áÊñôÂ∫´ÁµêÊßã..."
    
    # Â¶ÇÊûúÁµ±‰∏ÄË≥áÊñôÂ∫´Â∑≤Â≠òÂú®ÔºåÂÖàÂÇô‰ªΩ
    if [[ -f "$UNIFIED_DB" ]]; then
        log_warning "Áµ±‰∏ÄË≥áÊñôÂ∫´Â∑≤Â≠òÂú®ÔºåÂ∞áË¶ÜËìãÁèæÊúâÊ™îÊ°à"
    fi
    
    # ÂâµÂª∫Êñ∞ÁöÑÁµ±‰∏ÄË≥áÊñôÂ∫´
    cat > "$BACKUP_DIR/unified_schema.sql" << 'EOF'
-- Claude Night Pilot Áµ±‰∏ÄË≥áÊñôÂ∫´ÁµêÊßã
-- Âü∫Êñº SCHEDULER_COMPREHENSIVE_REFACTORING_PLAN.md

-- ÂïüÁî®Â§ñÈçµÁ¥ÑÊùü
PRAGMA foreign_keys = ON;

-- Prompts Ë°® (‰øùÊåÅÁèæÊúâÁµêÊßã)
CREATE TABLE IF NOT EXISTS prompts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT NOT NULL,
    content TEXT NOT NULL,
    tags TEXT,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Áµ±‰∏Ä Jobs Ë°® (Êï¥ÂêàÊâÄÊúâÁèæÊúâÂäüËÉΩ)
CREATE TABLE IF NOT EXISTS unified_jobs (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    prompt_id TEXT NOT NULL,
    cron_expression TEXT NOT NULL,
    status TEXT NOT NULL DEFAULT 'active',
    job_type TEXT NOT NULL DEFAULT 'scheduled',
    priority INTEGER DEFAULT 5,
    
    -- ‰ºÅÊ•≠Á¥öÂäüËÉΩ
    execution_count INTEGER DEFAULT 0,
    failure_count INTEGER DEFAULT 0,
    last_run_time TEXT,
    next_run_time TEXT,
    
    -- vibe-kanban Ê®°Âºè
    parent_job_id TEXT,
    
    -- Âü∑Ë°åÈÅ∏È†Ö (JSON)
    execution_options TEXT DEFAULT '{}',
    retry_config TEXT DEFAULT '{}',
    notification_config TEXT,
    
    -- Ê®ôÁ±§ËàáÂÖÉÊï∏Êìö
    tags TEXT DEFAULT '[]',
    metadata TEXT DEFAULT '{}',
    
    -- ÊôÇÈñìÊà≥
    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    created_by TEXT,
    
    FOREIGN KEY (parent_job_id) REFERENCES unified_jobs(id) ON DELETE CASCADE
);

-- ‰ªªÂãôÂü∑Ë°åÊµÅÁ®ãË°® (Âü∫Êñº vibe-kanban ExecutionProcess)
CREATE TABLE IF NOT EXISTS job_execution_processes (
    id TEXT PRIMARY KEY,
    job_id TEXT NOT NULL,
    process_type TEXT NOT NULL CHECK (process_type IN ('setup', 'execution', 'cleanup', 'validation')),
    status TEXT NOT NULL CHECK (status IN ('queued', 'running', 'completed', 'failed', 'cancelled', 'retrying')),
    start_time TEXT NOT NULL,
    end_time TEXT,
    output TEXT,
    error_message TEXT,
    retry_count INTEGER DEFAULT 0,
    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (job_id) REFERENCES unified_jobs(id) ON DELETE CASCADE
);

-- ‰ªªÂãôÂü∑Ë°åÁµêÊûúË°® (‰æÜËá™ RealTimeExecutor)
CREATE TABLE IF NOT EXISTS job_execution_results (
    id TEXT PRIMARY KEY,
    job_id TEXT NOT NULL,
    prompt_id TEXT NOT NULL,
    status TEXT NOT NULL,
    start_time TEXT NOT NULL,
    end_time TEXT NOT NULL,
    duration_ms INTEGER NOT NULL,
    output TEXT,
    error_message TEXT,
    retry_count INTEGER DEFAULT 0,
    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (job_id) REFERENCES unified_jobs(id) ON DELETE CASCADE
);

-- ‰ΩøÁî®ÈáèËøΩËπ§Ë°® (Âü∫Êñº ccusage Ê®°Âºè)
CREATE TABLE IF NOT EXISTS usage_tracking (
    id TEXT PRIMARY KEY,
    job_id TEXT,
    session_id TEXT,
    tokens_input INTEGER DEFAULT 0,
    tokens_output INTEGER DEFAULT 0,
    tokens_total INTEGER DEFAULT 0,
    cost_usd REAL DEFAULT 0.0,
    model_name TEXT,
    execution_duration_ms INTEGER DEFAULT 0,
    timestamp TEXT NOT NULL,
    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (job_id) REFERENCES unified_jobs(id) ON DELETE SET NULL
);

-- Á≥ªÁµ±ÈÖçÁΩÆË°®
CREATE TABLE IF NOT EXISTS system_config (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL,
    description TEXT,
    updated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- Á¥¢ÂºïÂÑ™Âåñ
CREATE INDEX IF NOT EXISTS idx_unified_jobs_status ON unified_jobs(status);
CREATE INDEX IF NOT EXISTS idx_unified_jobs_created_at ON unified_jobs(created_at);
CREATE INDEX IF NOT EXISTS idx_unified_jobs_parent ON unified_jobs(parent_job_id);
CREATE INDEX IF NOT EXISTS idx_execution_processes_job_id ON job_execution_processes(job_id);
CREATE INDEX IF NOT EXISTS idx_execution_processes_status ON job_execution_processes(status);
CREATE INDEX IF NOT EXISTS idx_execution_results_job_id ON job_execution_results(job_id);
CREATE INDEX IF NOT EXISTS idx_usage_tracking_job_id ON usage_tracking(job_id);
CREATE INDEX IF NOT EXISTS idx_usage_tracking_timestamp ON usage_tracking(timestamp);

-- ÊèíÂÖ•Á≥ªÁµ±ÈÖçÁΩÆ
INSERT OR REPLACE INTO system_config (key, value, description) VALUES
('database_version', '2.0.0-unified', 'Unified database schema version'),
('migration_date', datetime('now'), 'Date when migration was completed'),
('scheduler_type', 'unified', 'Type of scheduler implementation');
EOF

    # ÊáâÁî®Ë≥áÊñôÂ∫´ÁµêÊßã
    log_info "ÊáâÁî®Áµ±‰∏ÄË≥áÊñôÂ∫´ÁµêÊßãÂà∞ $UNIFIED_DB"
    sqlite3 "$UNIFIED_DB" < "$BACKUP_DIR/unified_schema.sql"
    log_success "Áµ±‰∏ÄË≥áÊñôÂ∫´ÁµêÊßãÂâµÂª∫ÂÆåÊàê"
}

# ÈÅ∑ÁßªËàäË≥áÊñôÂ∫´Ë≥áÊñô
migrate_legacy_data() {
    if [[ ! -f "$LEGACY_DB" ]]; then
        log_info "ËàäË≥áÊñôÂ∫´‰∏çÂ≠òÂú®ÔºåË∑≥ÈÅéË≥áÊñôÈÅ∑Áßª"
        return 0
    fi
    
    log_info "ÈñãÂßãÈÅ∑ÁßªËàäË≥áÊñôÂ∫´Ë≥áÊñô..."
    
    # ÈÅ∑Áßª prompts Ë°®
    if sqlite3 "$LEGACY_DB" ".schema prompts" &>/dev/null; then
        log_info "ÈÅ∑Áßª prompts Ë°®..."
        sqlite3 "$LEGACY_DB" ".output '$BACKUP_DIR/prompts_export.sql'" ".dump prompts"
        sqlite3 "$UNIFIED_DB" < "$BACKUP_DIR/prompts_export.sql" 2>/dev/null || true
        log_success "prompts Ë°®ÈÅ∑ÁßªÂÆåÊàê"
    fi
    
    # ÈÅ∑Áßª jobs Ë°®Âà∞ unified_jobs
    if sqlite3 "$LEGACY_DB" ".schema jobs" &>/dev/null; then
        log_info "ÈÅ∑Áßª jobs Ë°®Âà∞ unified_jobs..."
        
        # Â∞éÂá∫ jobs Ë≥áÊñô‰∏¶ËΩâÊèõÊ†ºÂºè
        sqlite3 -header -csv "$LEGACY_DB" "SELECT * FROM jobs;" > "$BACKUP_DIR/jobs_export.csv"
        
        # ÂâµÂª∫ËΩâÊèõËÖ≥Êú¨
        cat > "$BACKUP_DIR/convert_jobs.py" << 'EOF'
import csv
import sqlite3
import sys
import json
from datetime import datetime

def convert_jobs(legacy_csv, unified_db):
    conn = sqlite3.connect(unified_db)
    cursor = conn.cursor()
    
    with open(legacy_csv, 'r', encoding='utf-8') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            # ËΩâÊèõË≥áÊñôÊ†ºÂºè
            cursor.execute("""
                INSERT OR REPLACE INTO unified_jobs 
                (id, name, prompt_id, cron_expression, status, job_type, 
                 execution_count, failure_count, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                row.get('id', ''),
                row.get('name', ''),
                row.get('prompt_id', ''),
                row.get('cron_expression', ''),
                row.get('status', 'active'),
                row.get('job_type', 'scheduled'),
                int(row.get('execution_count', 0) or 0),
                int(row.get('failure_count', 0) or 0),
                row.get('created_at', datetime.now().isoformat()),
                row.get('updated_at', datetime.now().isoformat())
            ))
    
    conn.commit()
    conn.close()
    print(f"Converted jobs from {legacy_csv} to {unified_db}")

if __name__ == "__main__":
    convert_jobs(sys.argv[1], sys.argv[2])
EOF
        
        # Âü∑Ë°åËΩâÊèõ
        if command -v python3 &> /dev/null; then
            python3 "$BACKUP_DIR/convert_jobs.py" "$BACKUP_DIR/jobs_export.csv" "$UNIFIED_DB"
            log_success "jobs Ë°®ÈÅ∑ÁßªÂÆåÊàê"
        else
            log_warning "Python3 Êú™ÂÆâË£ùÔºåË∑≥ÈÅé jobs Ë°®Ëá™ÂãïËΩâÊèõ"
        fi
    fi
    
    # ÈÅ∑Áßª schedules Ë°®ÔºàÂ¶ÇÊûúÂ≠òÂú®Ôºâ
    if sqlite3 "$LEGACY_DB" ".schema schedules" &>/dev/null; then
        log_info "Ê™¢Ê∏¨Âà∞ schedules Ë°®ÔºåÈúÄË¶ÅÊâãÂãïÂêà‰ΩµÂà∞ unified_jobs"
        sqlite3 -header -csv "$LEGACY_DB" "SELECT * FROM schedules;" > "$BACKUP_DIR/schedules_export.csv"
        log_warning "schedules Ë°®Â∑≤Â∞éÂá∫Âà∞ $BACKUP_DIR/schedules_export.csvÔºåÈúÄË¶ÅÊâãÂãïÊ™¢Êü•ÂíåÂêà‰Ωµ"
    fi
}

# È©óË≠âÈÅ∑ÁßªÁµêÊûú
verify_migration() {
    log_info "È©óË≠âÈÅ∑ÁßªÁµêÊûú..."
    
    # Ê™¢Êü•Áµ±‰∏ÄË≥áÊñôÂ∫´ÁµêÊßã
    check_database_schema "$UNIFIED_DB" "Áµ±‰∏ÄË≥áÊñôÂ∫´"
    
    # ÊØîËºÉË®òÈåÑÊï∏Èáè
    if [[ -f "$LEGACY_DB" ]]; then
        log_info "ÊØîËºÉÈÅ∑ÁßªÂâçÂæåË≥áÊñôÊï∏Èáè..."
        
        # ÊØîËºÉ prompts Ë°®
        if sqlite3 "$LEGACY_DB" ".schema prompts" &>/dev/null && sqlite3 "$UNIFIED_DB" ".schema prompts" &>/dev/null; then
            local legacy_prompts=$(sqlite3 "$LEGACY_DB" "SELECT COUNT(*) FROM prompts;")
            local unified_prompts=$(sqlite3 "$UNIFIED_DB" "SELECT COUNT(*) FROM prompts;")
            
            if [[ "$legacy_prompts" -eq "$unified_prompts" ]]; then
                log_success "prompts Ë°®ÈÅ∑ÁßªÈ©óË≠âÈÄöÈÅé: $legacy_prompts = $unified_prompts"
            else
                log_warning "prompts Ë°®Êï∏Èáè‰∏ç‰∏ÄËá¥: Ëàä=$legacy_prompts, Êñ∞=$unified_prompts"
            fi
        fi
        
        # Ê™¢Êü• unified_jobs Ë°®
        local unified_jobs=$(sqlite3 "$UNIFIED_DB" "SELECT COUNT(*) FROM unified_jobs;" 2>/dev/null || echo "0")
        log_info "unified_jobs Ë°®Ë®òÈåÑÊï∏: $unified_jobs"
    fi
    
    # Ê™¢Êü•Ë≥áÊñôÂ∫´ÂÆåÊï¥ÊÄß
    local integrity_check=$(sqlite3 "$UNIFIED_DB" "PRAGMA integrity_check;")
    if [[ "$integrity_check" == "ok" ]]; then
        log_success "Ë≥áÊñôÂ∫´ÂÆåÊï¥ÊÄßÊ™¢Êü•ÈÄöÈÅé"
    else
        log_error "Ë≥áÊñôÂ∫´ÂÆåÊï¥ÊÄßÊ™¢Êü•Â§±Êïó: $integrity_check"
        return 1
    fi
}

# Êõ¥Êñ∞ÊáâÁî®ÈÖçÁΩÆ
update_application_config() {
    log_info "Êõ¥Êñ∞ÊáâÁî®ÈÖçÁΩÆ..."
    
    # ÂâµÂª∫ÈÖçÁΩÆÊõ¥Êñ∞ËÖ≥Êú¨
    cat > "$BACKUP_DIR/update_config.md" << EOF
# ÊáâÁî®ÈÖçÁΩÆÊõ¥Êñ∞ÊåáÂçó

## ÈúÄË¶ÅÊõ¥Êñ∞ÁöÑÊ™îÊ°à

1. **src-tauri/src/database_manager.rs**
   - Â∞áÊâÄÊúâ \`claude-pilot.db\` ÊîπÁÇ∫ \`claude-night-pilot.db\`
   - Êõ¥Êñ∞Ë°®ÂêçÁ®±Âæû \`jobs\` Âà∞ \`unified_jobs\`

2. **src-tauri/src/scheduler/real_time_executor.rs**
   - Á¢∫Ë™ç‰ΩøÁî® \`claude-night-pilot.db\`
   - Êõ¥Êñ∞Ë°®ÁµêÊßãÂ∞çÊáâÊñ∞ÁöÑ unified_jobs

3. **src-tauri/src/services/job_service.rs**
   - Êõ¥Êñ∞Êü•Ë©¢Ë™ûÂè•‰ΩøÁî® unified_jobs Ë°®
   - ÈÅ©ÈÖçÊñ∞ÁöÑË≥áÊñôÁµêÊßã

4. **Ê∏¨Ë©¶Ê™îÊ°à**
   - Êõ¥Êñ∞ÊâÄÊúâÊ∏¨Ë©¶‰∏≠ÁöÑË≥áÊñôÂ∫´Ë∑ØÂæë
   - ‰øÆÊîπÊ∏¨Ë©¶Ë≥áÊñôÁµêÊßãÂ∞çÊáâÊñ∞Ë°®

## È©óË≠âÊ≠•È©ü

1. Âü∑Ë°åÊ∏¨Ë©¶Â•ó‰ª∂Á¢∫‰øùÂäüËÉΩÊ≠£Â∏∏
2. Ê™¢Êü•Êó•Ë™å‰∏≠ÊòØÂê¶ÊúâË≥áÊñôÂ∫´Ë∑ØÂæëÈåØË™§
3. È©óË≠âÊéíÁ®ãÂô®ÂäüËÉΩÊòØÂê¶Ê≠£Â∏∏ÈÅã‰Ωú

## ÂõûÊªæÊåáÂçó

Â¶ÇÊûúÈÅ∑ÁßªÂá∫ÁèæÂïèÈ°åÔºåÂèØ‰ª•ÂæûÂÇô‰ªΩÊÅ¢Âæ©Ôºö
\`\`\`bash
cp $BACKUP_DIR/claude-pilot-backup.db claude-pilot.db
cp $BACKUP_DIR/claude-night-pilot-backup.db claude-night-pilot.db
\`\`\`
EOF
    
    log_success "ÈÖçÁΩÆÊõ¥Êñ∞ÊåáÂçóÂ∑≤ÂâµÂª∫: $BACKUP_DIR/update_config.md"
}

# Ê∏ÖÁêÜËá®ÊôÇÊ™îÊ°à
cleanup_temporary_files() {
    log_info "Ê∏ÖÁêÜËá®ÊôÇÊ™îÊ°à..."
    
    # ‰øùÁïôÈáçË¶ÅÁöÑÂÇô‰ªΩÂíåÊó•Ë™åÔºåÊ∏ÖÁêÜÂÖ∂‰ªñËá®ÊôÇÊ™îÊ°à
    rm -f "$BACKUP_DIR/convert_jobs.py" 2>/dev/null || true
    rm -f "$BACKUP_DIR/prompts_export.sql" 2>/dev/null || true
    
    log_success "Ëá®ÊôÇÊ™îÊ°àÊ∏ÖÁêÜÂÆåÊàê"
}

# ÁîüÊàêÈÅ∑ÁßªÂ†±Âëä
generate_migration_report() {
    log_info "ÁîüÊàêÈÅ∑ÁßªÂ†±Âëä..."
    
    cat > "$BACKUP_DIR/migration_report.md" << EOF
# Claude Night Pilot Ë≥áÊñôÂ∫´ÈÅ∑ÁßªÂ†±Âëä

**ÈÅ∑ÁßªÊôÇÈñì**: $(date)
**ÈÅ∑ÁßªÁâàÊú¨**: ÂæûÂàÜÊï£ÂºèË≥áÊñôÂ∫´Âà∞Áµ±‰∏ÄË≥áÊñôÂ∫´ v2.0.0
**ÂÇô‰ªΩ‰ΩçÁΩÆ**: $BACKUP_DIR

## ÈÅ∑ÁßªÊëòË¶Å

### Ê™îÊ°àËÆäÊõ¥
- **ËàäË≥áÊñôÂ∫´**: $LEGACY_DB $(if [[ -f "$LEGACY_DB" ]]; then echo "‚úÖ Â∑≤ÂÇô‰ªΩ"; else echo "‚ùå ‰∏çÂ≠òÂú®"; fi)
- **Áµ±‰∏ÄË≥áÊñôÂ∫´**: $UNIFIED_DB ‚úÖ Â∑≤ÂâµÂª∫

### Ë≥áÊñôÈÅ∑ÁßªÁãÄÊÖã
$(if [[ -f "$LEGACY_DB" ]]; then
    echo "- Prompts Ë°®: $(sqlite3 "$LEGACY_DB" "SELECT COUNT(*) FROM prompts;" 2>/dev/null || echo "0") Á≠ÜË®òÈåÑÂ∑≤ÈÅ∑Áßª"
    if sqlite3 "$LEGACY_DB" ".schema jobs" &>/dev/null; then
        echo "- Jobs Ë°®: $(sqlite3 "$LEGACY_DB" "SELECT COUNT(*) FROM jobs;" 2>/dev/null || echo "0") Á≠ÜË®òÈåÑÂ∑≤ËΩâÊèõÁÇ∫ unified_jobs"
    fi
    if sqlite3 "$LEGACY_DB" ".schema schedules" &>/dev/null; then
        echo "- Schedules Ë°®: $(sqlite3 "$LEGACY_DB" "SELECT COUNT(*) FROM schedules;" 2>/dev/null || echo "0") Á≠ÜË®òÈåÑÈúÄË¶ÅÊâãÂãïÊ™¢Êü•"
    fi
else
    echo "- ËàäË≥áÊñôÂ∫´‰∏çÂ≠òÂú®ÔºåÂª∫Á´ãÂÖ®Êñ∞Áµ±‰∏ÄË≥áÊñôÂ∫´"
fi)

### Êñ∞Ë≥áÊñôÂ∫´ÁµêÊßã
- unified_jobs: Áµ±‰∏Ä‰ªªÂãôË°®
- job_execution_processes: Âü∑Ë°åÊµÅÁ®ãËøΩËπ§
- job_execution_results: Âü∑Ë°åÁµêÊûúË®òÈåÑ
- usage_tracking: ‰ΩøÁî®ÈáèËøΩËπ§
- system_config: Á≥ªÁµ±ÈÖçÁΩÆ

## ÂæåÁ∫åË°åÂãïÈ†ÖÁõÆ

1. **Á´ãÂç≥Ë°åÂãï**
   - [ ] Êõ¥Êñ∞ÊáâÁî®Á®ãÂºèÁ¢º‰∏≠ÁöÑË≥áÊñôÂ∫´Ë∑ØÂæë
   - [ ] ‰øÆÊîπË°®ÂêçÁ®±Âæû jobs Âà∞ unified_jobs
   - [ ] Âü∑Ë°åÂÆåÊï¥Ê∏¨Ë©¶Â•ó‰ª∂

2. **È©óË≠âÊ∏¨Ë©¶**
   - [ ] ÊéíÁ®ãÂô®ÂäüËÉΩÊ∏¨Ë©¶
   - [ ] Ë≥áÊñôÂÆåÊï¥ÊÄßÊ∏¨Ë©¶
   - [ ] ÊÄßËÉΩÂü∫Ê∫ñÊ∏¨Ë©¶

3. **Ê∏ÖÁêÜÂ∑•‰Ωú**
   - [ ] Á¢∫Ë™çÊñ∞Á≥ªÁµ±Á©©ÂÆöÂæåÔºåÂèØ‰ª•Âà™Èô§ËàäË≥áÊñôÂ∫´Ê™îÊ°à
   - [ ] Êõ¥Êñ∞ÊñáÊ™îÂíåÈÉ®ÁΩ≤ËÖ≥Êú¨

## ÂõûÊªæË®àÂäÉ

Â¶ÇÊûúÈúÄË¶ÅÂõûÊªæÂà∞ËàäÁâàÊú¨Ôºö
\`\`\`bash
cd $(pwd)
cp $BACKUP_DIR/claude-pilot-backup.db claude-pilot.db
rm claude-night-pilot.db
git checkout HEAD~1  # ÂõûÂà∞ÈÅ∑ÁßªÂâçÁöÑÁ®ãÂºèÁ¢ºÁâàÊú¨
\`\`\`

## ÊîØÊè¥Ë≥áÊ∫ê

- ÂÇô‰ªΩÊ™îÊ°à: $BACKUP_DIR/
- ÈÅ∑ÁßªÊó•Ë™å: $MIGRATION_LOG
- ÈÖçÁΩÆÊåáÂçó: $BACKUP_DIR/update_config.md
- ÂïèÈ°åÂõûÂ†±: Ë´ãÊ™¢Êü•ÈÅ∑ÁßªÊó•Ë™åÊ™îÊ°à

---
**ÁãÄÊÖã**: ‚úÖ ÈÅ∑ÁßªÂÆåÊàê
**‰∏ã‰∏ÄÊ≠•**: Ë´ãÊåâÁÖßÈÖçÁΩÆÊõ¥Êñ∞ÊåáÂçó‰øÆÊîπÊáâÁî®Á®ãÂºèÁ¢º
EOF

    log_success "ÈÅ∑ÁßªÂ†±ÂëäÂ∑≤ÁîüÊàê: $BACKUP_DIR/migration_report.md"
}

# ‰∏ªÂü∑Ë°åÂáΩÊï∏
main() {
    echo "üö® Claude Night Pilot - Á∑äÊÄ•Ë≥áÊñôÂ∫´Ë∑ØÂæëÁµ±‰∏ÄÂ∑•ÂÖ∑"
    echo "=================================================="
    echo ""
    
    # Âü∑Ë°åÈÅ∑ÁßªÊ≠•È©ü
    check_dependencies
    create_backup_directory
    backup_existing_databases
    check_database_schema "$LEGACY_DB" "ËàäË≥áÊñôÂ∫´" || true
    check_database_schema "$UNIFIED_DB" "Áµ±‰∏ÄË≥áÊñôÂ∫´" || true
    create_unified_database
    migrate_legacy_data
    verify_migration
    update_application_config
    cleanup_temporary_files
    generate_migration_report
    
    echo ""
    echo "üéâ Ë≥áÊñôÂ∫´ÈÅ∑ÁßªÂÆåÊàêÔºÅ"
    echo ""
    echo "üìã ‰∏ã‰∏ÄÊ≠•Ë°åÂãïÔºö"
    echo "1. Ê™¢Êü•ÈÅ∑ÁßªÂ†±Âëä: $BACKUP_DIR/migration_report.md"
    echo "2. Èñ±ËÆÄÈÖçÁΩÆÊåáÂçó: $BACKUP_DIR/update_config.md"
    echo "3. Êõ¥Êñ∞ÊáâÁî®Á®ãÂºèÁ¢º‰∏≠ÁöÑË≥áÊñôÂ∫´Ë∑ØÂæë"
    echo "4. Âü∑Ë°åÊ∏¨Ë©¶Â•ó‰ª∂È©óË≠âÂäüËÉΩÊ≠£Â∏∏"
    echo ""
    echo "üîí ÂÇô‰ªΩ‰ΩçÁΩÆ: $BACKUP_DIR"
    echo "üìù ÈÅ∑ÁßªÊó•Ë™å: $MIGRATION_LOG"
    echo ""
    echo "‚ö†Ô∏è  ÈáçË¶ÅÊèêÈÜíÔºöË´ãÂú®Á¢∫Ë™çÊñ∞Á≥ªÁµ±Á©©ÂÆöÂæåÂÜçÂà™Èô§ÂÇô‰ªΩÊ™îÊ°à"
}

# Âü∑Ë°å‰∏ªÂáΩÊï∏
main "$@"