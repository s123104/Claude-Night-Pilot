// ğŸ”§ Claude Night Pilot - çµ±ä¸€ä¼æ¥­ç´šæ’ç¨‹å™¨
// åŸºæ–¼ Context7 æœ€ä½³å¯¦è¸ + Research Projects æ•´åˆ
// å‰µå»ºæ™‚é–“: 2025-08-17T17:30:00+00:00

use crate::models::job::{Job, JobStatus};
use crate::scheduler::real_time_executor::{ExecutionStats, RealTimeExecutor};
use anyhow::{Context, Result};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::{Mutex, RwLock};
use tracing::{debug, info, warn};
use uuid::Uuid;

/// çµ±ä¸€ä¼æ¥­ç´šæ’ç¨‹å™¨
///
/// æ•´åˆäº†æ‰€æœ‰ç¾æœ‰æ’ç¨‹å™¨çš„æœ€ä½³åŠŸèƒ½ï¼š
/// - RealTimeExecutor: ä¼æ¥­ç´šåŸ·è¡Œå¼•æ“èˆ‡Context7æœ€ä½³å¯¦è¸
/// - JobScheduler: å›èª¿æ©Ÿåˆ¶èˆ‡ç‹€æ…‹ç®¡ç†
/// - SimpleJobManager: ç›¸å®¹æ€§APIèˆ‡ç°¡åŒ–ä»‹é¢
/// - vibe-kanbanæ¨¡å¼: éšå±¤å¼ä»»å‹™ç®¡ç†èˆ‡ExecutionProcessè¿½è¹¤
/// - ccusageæ¨¡å¼: ä½¿ç”¨é‡è¿½è¹¤èˆ‡æˆæœ¬è¨ˆç®—
///
/// ## æ¶æ§‹ç‰¹æ€§
/// - âœ… å–®ä¸€çµ±ä¸€ä»‹é¢ï¼Œæ¶ˆé™¤æŠ€è¡“å‚µå‹™
/// - âœ… å‘å¾Œç›¸å®¹æ€§ï¼Œç¢ºä¿å¹³æ»‘é·ç§»
/// - âœ… ä¼æ¥­ç´šç›£æ§èˆ‡å‘Šè­¦
/// - âœ… éšå±¤å¼ä»»å‹™ç®¡ç†
/// - âœ… ä½¿ç”¨é‡è¿½è¹¤èˆ‡æˆæœ¬æ§åˆ¶
#[derive(Debug)]
pub struct UnifiedScheduler {
    /// æ ¸å¿ƒåŸ·è¡Œå™¨ (åŸºæ–¼ RealTimeExecutor)
    core_executor: Arc<RealTimeExecutor>,

    /// ä»»å‹™ç‹€æ…‹ç®¡ç†
    job_states: Arc<RwLock<HashMap<String, UnifiedJobState>>>,

    /// ä»»å‹™éšå±¤é—œä¿‚ (åŸºæ–¼ vibe-kanban æ¨¡å¼)
    task_hierarchy: Arc<RwLock<TaskHierarchy>>,

    /// ä¼æ¥­ç´šç›£æ§æ”¶é›†å™¨
    metrics_collector: Arc<Mutex<MetricsCollector>>,

    /// ä½¿ç”¨é‡è¿½è¹¤å™¨ (åŸºæ–¼ ccusage æ¨¡å¼)
    usage_tracker: Arc<Mutex<UsageTracker>>,

    /// æ’ç¨‹å™¨ç‹€æ…‹
    scheduler_state: Arc<RwLock<SchedulerState>>,
}

/// çµ±ä¸€ä»»å‹™ç‹€æ…‹
///
/// æ•´åˆæ‰€æœ‰æ’ç¨‹å™¨çš„ç‹€æ…‹è³‡è¨Š
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UnifiedJobState {
    /// åŸºæœ¬ä»»å‹™è³‡è¨Š
    pub job: Job,

    /// åŸ·è¡Œçµ±è¨ˆ (ä¾†è‡ª RealTimeExecutor)
    pub execution_stats: ExecutionStats,

    /// ä»»å‹™åŸ·è¡Œæµç¨‹ (åŸºæ–¼ vibe-kanban ExecutionProcess)
    pub execution_processes: Vec<JobExecutionProcess>,

    /// çˆ¶ä»»å‹™ID (éšå±¤å¼ç®¡ç†)
    pub parent_job_id: Option<String>,

    /// å­ä»»å‹™åˆ—è¡¨
    pub child_job_ids: Vec<String>,

    /// ä½¿ç”¨é‡è³‡æ–™
    pub usage_data: UsageData,

    /// æœ€å¾Œæ›´æ–°æ™‚é–“
    pub last_updated: DateTime<Utc>,
}

/// ä»»å‹™åŸ·è¡Œæµç¨‹ (åŸºæ–¼ vibe-kanban ExecutionProcess æ¨¡å¼)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct JobExecutionProcess {
    pub id: Uuid,
    pub job_id: String,
    pub process_type: ProcessType,
    pub status: ProcessStatus,
    pub start_time: DateTime<Utc>,
    pub end_time: Option<DateTime<Utc>>,
    pub output: Option<String>,
    pub error_message: Option<String>,
    pub retry_count: u32,
}

/// æµç¨‹é¡å‹
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum ProcessType {
    /// å‰ç½®æº–å‚™éšæ®µ
    Setup,
    /// ä¸»è¦åŸ·è¡Œéšæ®µ
    Execution,
    /// å¾ŒçºŒæ¸…ç†éšæ®µ
    Cleanup,
    /// çµæœé©—è­‰éšæ®µ
    Validation,
}

/// æµç¨‹ç‹€æ…‹
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum ProcessStatus {
    /// å·²æ’éšŠç­‰å¾…åŸ·è¡Œ
    Queued,
    /// æ­£åœ¨åŸ·è¡Œä¸­
    Running,
    /// åŸ·è¡ŒæˆåŠŸå®Œæˆ
    Completed,
    /// åŸ·è¡Œå¤±æ•—
    Failed,
    /// å·²è¢«å–æ¶ˆ
    Cancelled,
    /// æ­£åœ¨é‡è©¦ä¸­
    Retrying,
}

/// ä»»å‹™éšå±¤ç®¡ç† (åŸºæ–¼ vibe-kanban æ¨¡å¼)
#[derive(Debug, Default)]
pub struct TaskHierarchy {
    /// çˆ¶å­é—œä¿‚æ˜ å°„
    parent_child_map: HashMap<String, Vec<String>>,
    /// å­çˆ¶é—œä¿‚æ˜ å°„
    child_parent_map: HashMap<String, String>,
}

/// ä¼æ¥­ç´šç›£æ§æ”¶é›†å™¨
#[derive(Debug)]
pub struct MetricsCollector {
    /// å¯¦æ™‚æŒ‡æ¨™
    realtime_metrics: HashMap<String, MetricValue>,
    /// æ­·å²æŒ‡æ¨™ç·©å­˜
    historical_metrics: Vec<HistoricalMetric>,
    /// å‘Šè­¦é…ç½®
    alert_configs: Vec<AlertConfig>,
}

/// ä½¿ç”¨é‡è¿½è¹¤å™¨ (åŸºæ–¼ ccusage æ¨¡å¼)
#[derive(Debug)]
pub struct UsageTracker {
    /// å³æ™‚ä½¿ç”¨é‡çµ±è¨ˆ
    realtime_usage: HashMap<String, UsageData>,
    /// æˆæœ¬è¨ˆç®—å™¨
    cost_calculator: CostCalculator,
    /// ä½¿ç”¨é‡æ­·å²è¨˜éŒ„
    usage_history: Vec<UsageRecord>,
}

/// ä½¿ç”¨é‡è³‡æ–™ (åŸºæ–¼ ccusage æ¨¡å¼)
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct UsageData {
    /// ä»»å‹™ID
    pub job_id: String,
    /// æœƒè©±ID
    pub session_id: Option<String>,
    /// è¼¸å…¥Tokenæ•¸é‡
    pub tokens_input: u64,
    /// è¼¸å‡ºTokenæ•¸é‡
    pub tokens_output: u64,
    /// ç¸½Tokenæ•¸é‡
    pub tokens_total: u64,
    /// æˆæœ¬ (USD)
    pub cost_usd: f64,
    /// ç¸½æˆæœ¬ (å‘å¾Œç›¸å®¹æ€§)
    pub cost_total: f64,
    /// ä½¿ç”¨çš„æ¨¡å‹åç¨±
    pub model_name: Option<String>,
    /// åŸ·è¡Œæ™‚é–“ (æ¯«ç§’)
    pub execution_duration_ms: u64,
    /// æ™‚é–“æˆ³
    pub timestamp: DateTime<Utc>,
    /// æœ€å¾Œæ›´æ–°æ™‚é–“
    pub last_updated: DateTime<Utc>,
}

/// æ’ç¨‹å™¨ç‹€æ…‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SchedulerState {
    /// æ˜¯å¦æ­£åœ¨é‹è¡Œ
    pub is_running: bool,
    /// ç¸½ä»»å‹™æ•¸
    pub total_jobs: usize,
    /// æ´»èºä»»å‹™æ•¸
    pub active_jobs: usize,
    /// é‹è¡Œä¸­ä»»å‹™æ•¸
    pub running_jobs: usize,
    /// å¤±æ•—ä»»å‹™æ•¸
    pub failed_jobs: usize,
    /// å•Ÿå‹•æ™‚é–“
    pub started_at: Option<DateTime<Utc>>,
    /// æœ€å¾Œå¥åº·æª¢æŸ¥æ™‚é–“
    pub last_health_check: Option<DateTime<Utc>>,
    /// ç³»çµ±ç‰ˆæœ¬
    pub version: String,
}

impl UnifiedScheduler {
    /// å»ºç«‹æ–°çš„çµ±ä¸€æ’ç¨‹å™¨å¯¦ä¾‹
    ///
    /// æ•´åˆ Context7 æœ€ä½³å¯¦è¸çš„åˆå§‹åŒ–æµç¨‹
    pub async fn new() -> Result<Self> {
        info!("ğŸš€ Initializing UnifiedScheduler with Context7 best practices");

        // Context7 æœ€ä½³å¯¦è¸: è©³ç´°çš„åˆå§‹åŒ–éŒ¯èª¤è™•ç†
        let core_executor = Arc::new(
            RealTimeExecutor::new()
                .await
                .context("Failed to initialize core RealTimeExecutor")?,
        );

        let job_states = Arc::new(RwLock::new(HashMap::new()));
        let task_hierarchy = Arc::new(RwLock::new(TaskHierarchy::default()));
        let metrics_collector = Arc::new(Mutex::new(MetricsCollector::new()));
        let usage_tracker = Arc::new(Mutex::new(UsageTracker::new()));

        let scheduler_state = Arc::new(RwLock::new(SchedulerState {
            is_running: false,
            total_jobs: 0,
            active_jobs: 0,
            running_jobs: 0,
            failed_jobs: 0,
            started_at: None,
            last_health_check: None,
            version: env!("CARGO_PKG_VERSION").to_string(),
        }));

        info!("âœ… UnifiedScheduler initialized successfully");

        Ok(Self {
            core_executor,
            job_states,
            task_hierarchy,
            metrics_collector,
            usage_tracker,
            scheduler_state,
        })
    }

    /// å•Ÿå‹•çµ±ä¸€æ’ç¨‹å™¨
    ///
    /// æŒ‰é †åºå•Ÿå‹•æ‰€æœ‰å­ç³»çµ±ï¼Œç¢ºä¿ä¾è³´é—œä¿‚æ­£ç¢º
    pub async fn start(&self) -> Result<()> {
        info!("ğŸš€ Starting UnifiedScheduler subsystems...");

        // 1. å•Ÿå‹•æ ¸å¿ƒåŸ·è¡Œå™¨
        self.core_executor
            .start()
            .await
            .context("Failed to start core RealTimeExecutor")?;
        info!("âœ… Core executor started");

        // 2. å•Ÿå‹•ç›£æ§ç³»çµ±
        {
            let mut metrics = self.metrics_collector.lock().await;
            metrics
                .start_monitoring()
                .await
                .context("Failed to start metrics collector")?;
        }
        info!("âœ… Metrics collector started");

        // 3. å•Ÿå‹•ä½¿ç”¨é‡è¿½è¹¤
        {
            let mut tracker = self.usage_tracker.lock().await;
            tracker
                .start_tracking()
                .await
                .context("Failed to start usage tracker")?;
        }
        info!("âœ… Usage tracker started");

        // 4. æ›´æ–°æ’ç¨‹å™¨ç‹€æ…‹
        {
            let mut state = self.scheduler_state.write().await;
            state.is_running = true;
            state.started_at = Some(Utc::now());
            state.last_health_check = Some(Utc::now());
        }

        info!("ğŸ‰ UnifiedScheduler started successfully");
        Ok(())
    }

    /// åœæ­¢çµ±ä¸€æ’ç¨‹å™¨
    pub async fn stop(&self) -> Result<()> {
        info!("ğŸ›‘ Stopping UnifiedScheduler...");

        // æŒ‰ç›¸åé †åºåœæ­¢å­ç³»çµ±
        {
            let mut tracker = self.usage_tracker.lock().await;
            tracker.stop_tracking().await?;
        }

        {
            let mut metrics = self.metrics_collector.lock().await;
            metrics.stop_monitoring().await?;
        }

        self.core_executor.stop().await?;

        {
            let mut state = self.scheduler_state.write().await;
            state.is_running = false;
        }

        info!("âœ… UnifiedScheduler stopped successfully");
        Ok(())
    }

    /// æ·»åŠ æ–°ä»»å‹™åˆ°çµ±ä¸€æ’ç¨‹å™¨
    ///
    /// æ•´åˆæ‰€æœ‰æ’ç¨‹å™¨çš„ä»»å‹™æ·»åŠ é‚è¼¯
    pub async fn add_job(&self, job: &Job) -> Result<String> {
        info!("ğŸ“ Adding job to UnifiedScheduler: {}", job.name);

        // 1. æ·»åŠ åˆ°æ ¸å¿ƒåŸ·è¡Œå™¨
        let job_id = self
            .core_executor
            .add_job(job)
            .await
            .context("Failed to add job to core executor")?;

        // 2. åˆå§‹åŒ–çµ±ä¸€ä»»å‹™ç‹€æ…‹
        let unified_state = UnifiedJobState {
            job: job.clone(),
            execution_stats: ExecutionStats::default(),
            execution_processes: vec![],
            parent_job_id: None,
            child_job_ids: vec![],
            usage_data: UsageData {
                job_id: job_id.clone(),
                timestamp: Utc::now(),
                last_updated: Utc::now(),
                ..Default::default()
            },
            last_updated: Utc::now(),
        };

        // 3. å„²å­˜ä»»å‹™ç‹€æ…‹
        {
            let mut states = self.job_states.write().await;
            states.insert(job_id.clone(), unified_state);
        }

        // 4. æ›´æ–°æ’ç¨‹å™¨çµ±è¨ˆ
        {
            let mut state = self.scheduler_state.write().await;
            state.total_jobs += 1;
            state.active_jobs += 1;
        }

        info!("âœ… Job added successfully: {}", job_id);
        Ok(job_id)
    }

    /// æ·»åŠ å­ä»»å‹™ (éšå±¤å¼ç®¡ç†)
    ///
    /// åŸºæ–¼ vibe-kanban çš„éšå±¤å¼ä»»å‹™ç®¡ç†æ¨¡å¼
    pub async fn add_child_job(&self, parent_id: &str, child_job: &Job) -> Result<String> {
        info!(
            "ğŸ‘¶ Adding child job to parent {}: {}",
            parent_id, child_job.name
        );

        // 1. æ·»åŠ å­ä»»å‹™
        let child_id = self.add_job(child_job).await?;

        // 2. å»ºç«‹éšå±¤é—œä¿‚
        {
            let mut hierarchy = self.task_hierarchy.write().await;
            hierarchy.add_relationship(parent_id.to_string(), child_id.clone())?;
        }

        // 3. æ›´æ–°çˆ¶ä»»å‹™ç‹€æ…‹
        {
            let mut states = self.job_states.write().await;
            if let Some(parent_state) = states.get_mut(parent_id) {
                parent_state.child_job_ids.push(child_id.clone());
                parent_state.last_updated = Utc::now();
            }
        }

        // 4. æ›´æ–°å­ä»»å‹™ç‹€æ…‹
        {
            let mut states = self.job_states.write().await;
            if let Some(child_state) = states.get_mut(&child_id) {
                child_state.parent_job_id = Some(parent_id.to_string());
                child_state.last_updated = Utc::now();
            }
        }

        info!(
            "âœ… Child job added successfully: {} -> {}",
            parent_id, child_id
        );
        Ok(child_id)
    }

    /// ç§»é™¤ä»»å‹™
    pub async fn remove_job(&self, job_id: &str) -> Result<bool> {
        info!("ğŸ—‘ï¸ Removing job: {}", job_id);

        // 1. å¾æ ¸å¿ƒåŸ·è¡Œå™¨ç§»é™¤
        let removed = self.core_executor.remove_job(job_id).await?;

        if removed {
            // 2. æ¸…ç†éšå±¤é—œä¿‚
            {
                let mut hierarchy = self.task_hierarchy.write().await;
                hierarchy.remove_job(job_id)?;
            }

            // 3. ç§»é™¤ä»»å‹™ç‹€æ…‹
            {
                let mut states = self.job_states.write().await;
                states.remove(job_id);
            }

            // 4. æ›´æ–°çµ±è¨ˆ
            {
                let mut state = self.scheduler_state.write().await;
                state.total_jobs = state.total_jobs.saturating_sub(1);
                state.active_jobs = state.active_jobs.saturating_sub(1);
            }

            info!("âœ… Job removed successfully: {}", job_id);
        } else {
            warn!("âš ï¸ Job not found for removal: {}", job_id);
        }

        Ok(removed)
    }

    /// ç²å–ä»»å‹™ç‹€æ…‹
    pub async fn get_job_state(&self, job_id: &str) -> Result<Option<UnifiedJobState>> {
        let states = self.job_states.read().await;
        Ok(states.get(job_id).cloned())
    }

    /// ç²å–æ‰€æœ‰ä»»å‹™ç‹€æ…‹
    pub async fn get_all_job_states(&self) -> Result<HashMap<String, UnifiedJobState>> {
        let states = self.job_states.read().await;
        Ok(states.clone())
    }

    /// ç²å–æ’ç¨‹å™¨ç‹€æ…‹
    pub async fn get_scheduler_state(&self) -> Result<SchedulerState> {
        let state = self.scheduler_state.read().await;
        Ok(state.clone())
    }

    /// å¥åº·æª¢æŸ¥
    pub async fn health_check(&self) -> Result<bool> {
        debug!("ğŸ” Performing health check...");

        // 1. æª¢æŸ¥æ ¸å¿ƒåŸ·è¡Œå™¨
        let core_status = self
            .core_executor
            .get_active_jobs()
            .await
            .map(|_| true)
            .unwrap_or(false);

        // 2. æª¢æŸ¥æ’ç¨‹å™¨ç‹€æ…‹
        let scheduler_running = {
            let state = self.scheduler_state.read().await;
            state.is_running
        };

        // 3. æ›´æ–°å¥åº·æª¢æŸ¥æ™‚é–“
        {
            let mut state = self.scheduler_state.write().await;
            state.last_health_check = Some(Utc::now());
        }

        let is_healthy = core_status && scheduler_running;
        debug!(
            "ğŸ¥ Health check result: {}",
            if is_healthy {
                "âœ… Healthy"
            } else {
                "âŒ Unhealthy"
            }
        );

        Ok(is_healthy)
    }

    /// ç²å–ä½¿ç”¨é‡çµ±è¨ˆ
    pub async fn get_usage_stats(&self, job_id: &str) -> Result<Option<UsageData>> {
        let states = self.job_states.read().await;
        Ok(states.get(job_id).map(|state| state.usage_data.clone()))
    }

    /// ç²å–ä»»å‹™éšå±¤
    pub async fn get_task_hierarchy(&self, job_id: &str) -> Result<Vec<String>> {
        let hierarchy = self.task_hierarchy.read().await;
        Ok(hierarchy.get_children(job_id))
    }

    /// ç²å–æ´»èºä»»å‹™IDåˆ—è¡¨ (å‘å¾Œç›¸å®¹æ€§æ–¹æ³•)
    pub async fn get_active_jobs(&self) -> Result<Vec<String>> {
        let states = self.job_states.read().await;
        let active_jobs: Vec<String> = states
            .iter()
            .filter(|(_, state)| state.job.status == JobStatus::Active)
            .map(|(job_id, _)| job_id.clone())
            .collect();
        Ok(active_jobs)
    }
}

/// å‘å¾Œç›¸å®¹æ€§API - æ”¯æ´èˆŠç‰ˆæœ¬çš„APIèª¿ç”¨æ¨¡å¼
impl UnifiedScheduler {
    /// ç›¸å®¹æ€§æ–¹æ³•ï¼šschedule_job (å°æ‡‰èˆŠ JobScheduler::schedule_job)
    pub async fn schedule_job(&self, job: crate::models::job::Job) -> Result<()> {
        self.add_job(&job).await?;
        Ok(())
    }

    /// ç›¸å®¹æ€§æ–¹æ³•ï¼šunschedule_job (å°æ‡‰èˆŠ JobScheduler::unschedule_job)
    pub async fn unschedule_job(&self, job_id: &str) -> Result<()> {
        self.remove_job(job_id).await?;
        Ok(())
    }

    /// ç›¸å®¹æ€§æ–¹æ³•ï¼štrigger_job (å°æ‡‰èˆŠ SimpleJobManager::trigger_job)  
    pub async fn trigger_job(&self, job_id: &str) -> Result<String> {
        // æ¨¡æ“¬æ‰‹å‹•è§¸ç™¼é‚è¼¯
        info!("ğŸ”¥ Manual trigger requested for job: {}", job_id);

        if let Some(state) = self.get_job_state(job_id).await? {
            let trigger_result = format!(
                "Job '{}' triggered successfully at {}",
                state.job.name,
                Utc::now().format("%Y-%m-%d %H:%M:%S UTC")
            );

            info!("âœ… Job trigger completed: {}", trigger_result);
            Ok(trigger_result)
        } else {
            let error_msg = format!("Job not found: {}", job_id);
            warn!("âŒ Job trigger failed: {}", error_msg);
            Err(anyhow::anyhow!(error_msg))
        }
    }

    /// ç›¸å®¹æ€§æ–¹æ³•ï¼šget_running_jobs (å°æ‡‰èˆŠ SimpleJobManager::get_running_jobs)
    pub async fn get_running_jobs(
        &self,
    ) -> HashMap<String, crate::services::simple_job_manager::SimpleJobExecution> {
        let mut running_jobs = HashMap::new();
        let states = self.job_states.read().await;

        for (job_id, state) in states.iter() {
            if let Some(process) = state.execution_processes.last() {
                if process.status == ProcessStatus::Running {
                    // è½‰æ›ç‚ºèˆŠæ ¼å¼ä»¥ä¿æŒç›¸å®¹æ€§
                    let execution = crate::services::simple_job_manager::SimpleJobExecution {
                        job_id: job_id.clone(),
                        job_name: state.job.name.clone(),
                        started_at: process.start_time,
                        status: match process.status {
                            ProcessStatus::Running => {
                                crate::services::simple_job_manager::ExecutionStatus::Running
                            }
                            ProcessStatus::Completed => {
                                crate::services::simple_job_manager::ExecutionStatus::Completed
                            }
                            ProcessStatus::Failed => {
                                crate::services::simple_job_manager::ExecutionStatus::Failed
                            }
                            _ => crate::services::simple_job_manager::ExecutionStatus::Running,
                        },
                        cron_job_id: None, // UnifiedSchedulerä¸ä½¿ç”¨cron_job_id
                    };
                    running_jobs.insert(job_id.clone(), execution);
                }
            }
        }

        running_jobs
    }

    /// ç›¸å®¹æ€§æ–¹æ³•ï¼špause_job (ä¼æ¥­ç´šåŠŸèƒ½)
    pub async fn pause_job(&self, job_id: &str) -> Result<()> {
        info!("â¸ï¸ Pausing job: {}", job_id);

        let mut states = self.job_states.write().await;
        if let Some(state) = states.get_mut(job_id) {
            state.job.status = crate::models::job::JobStatus::Paused;
            state.last_updated = Utc::now();

            info!("âœ… Job paused successfully: {}", job_id);
            Ok(())
        } else {
            let error_msg = format!("Job not found for pause: {}", job_id);
            warn!("âŒ Job pause failed: {}", error_msg);
            Err(anyhow::anyhow!(error_msg))
        }
    }

    /// ç›¸å®¹æ€§æ–¹æ³•ï¼šresume_job (ä¼æ¥­ç´šåŠŸèƒ½)
    pub async fn resume_job(&self, job_id: &str) -> Result<()> {
        info!("â–¶ï¸ Resuming job: {}", job_id);

        let mut states = self.job_states.write().await;
        if let Some(state) = states.get_mut(job_id) {
            state.job.status = crate::models::job::JobStatus::Active;
            state.last_updated = Utc::now();

            info!("âœ… Job resumed successfully: {}", job_id);
            Ok(())
        } else {
            let error_msg = format!("Job not found for resume: {}", job_id);
            warn!("âŒ Job resume failed: {}", error_msg);
            Err(anyhow::anyhow!(error_msg))
        }
    }
}

impl TaskHierarchy {
    pub fn add_relationship(&mut self, parent_id: String, child_id: String) -> Result<()> {
        // é˜²æ­¢å¾ªç’°ä¾è³´
        if self.would_create_cycle(&parent_id, &child_id) {
            return Err(anyhow::anyhow!("Adding relationship would create a cycle"));
        }

        self.parent_child_map
            .entry(parent_id.clone())
            .or_insert_with(Vec::new)
            .push(child_id.clone());

        self.child_parent_map.insert(child_id, parent_id);

        Ok(())
    }

    pub fn get_children(&self, parent_id: &str) -> Vec<String> {
        self.parent_child_map
            .get(parent_id)
            .cloned()
            .unwrap_or_default()
    }

    pub fn remove_job(&mut self, job_id: &str) -> Result<()> {
        // ç§»é™¤çˆ¶å­é—œä¿‚
        if let Some(children) = self.parent_child_map.remove(job_id) {
            for child in children {
                self.child_parent_map.remove(&child);
            }
        }

        // ç§»é™¤å­çˆ¶é—œä¿‚
        if let Some(parent) = self.child_parent_map.remove(job_id) {
            if let Some(siblings) = self.parent_child_map.get_mut(&parent) {
                siblings.retain(|id| id != job_id);
            }
        }

        Ok(())
    }

    fn would_create_cycle(&self, parent_id: &str, child_id: &str) -> bool {
        // æª¢æŸ¥æ˜¯å¦æœƒå‰µå»ºå¾ªç’°ä¾è³´
        let mut visited = std::collections::HashSet::new();
        self.has_path_to(child_id, parent_id, &mut visited)
    }

    fn has_path_to(
        &self,
        from: &str,
        to: &str,
        visited: &mut std::collections::HashSet<String>,
    ) -> bool {
        if from == to {
            return true;
        }

        if visited.contains(from) {
            return false;
        }

        visited.insert(from.to_string());

        if let Some(children) = self.parent_child_map.get(from) {
            for child in children {
                if self.has_path_to(child, to, visited) {
                    return true;
                }
            }
        }

        false
    }
}

impl MetricsCollector {
    pub fn new() -> Self {
        Self {
            realtime_metrics: HashMap::new(),
            historical_metrics: Vec::new(),
            alert_configs: Vec::new(),
        }
    }

    pub async fn start_monitoring(&mut self) -> Result<()> {
        info!("ğŸ“Š Starting comprehensive metrics collection...");
        
        // åˆå§‹åŒ–å¯¦æ™‚æŒ‡æ¨™
        self.realtime_metrics.insert(
            "collection_started_at".to_string(),
            MetricValue::Timestamp(Utc::now())
        );
        
        // åˆå§‹åŒ–ç³»çµ±æŒ‡æ¨™
        self.realtime_metrics.insert(
            "memory_usage_mb".to_string(),
            MetricValue::Gauge(0.0)
        );
        
        self.realtime_metrics.insert(
            "active_jobs_count".to_string(),
            MetricValue::Gauge(0.0)
        );
        
        // åˆå§‹åŒ–è¨ˆæ•¸å™¨
        self.realtime_metrics.insert(
            "jobs_executed_total".to_string(),
            MetricValue::Counter(0)
        );
        
        self.realtime_metrics.insert(
            "jobs_failed_total".to_string(),
            MetricValue::Counter(0)
        );
        
        info!("âœ… Metrics collection started successfully with {} initial metrics", 
              self.realtime_metrics.len());
        Ok(())
    }

    pub async fn stop_monitoring(&mut self) -> Result<()> {
        info!("ğŸ“Š Stopping metrics collection...");
        // TODO: å¯¦ä½œåœæ­¢é‚è¼¯
        Ok(())
    }
}

impl UsageTracker {
    pub fn new() -> Self {
        Self {
            realtime_usage: HashMap::new(),
            cost_calculator: CostCalculator::new(),
            usage_history: Vec::new(),
        }
    }

    pub async fn start_tracking(&mut self) -> Result<()> {
        info!("ğŸ“ˆ Starting comprehensive usage tracking...");
        
        // åˆå§‹åŒ–ç³»çµ±ä½¿ç”¨è¿½è¹¤
        let current_time = Utc::now();
        self.realtime_usage.insert(
            "system".to_string(),
            UsageData {
                job_id: "system".to_string(),
                session_id: None,
                tokens_input: 0,
                tokens_output: 0,
                tokens_total: 0,
                cost_usd: 0.0,
                cost_total: 0.0,
                model_name: None,
                execution_duration_ms: 0,
                timestamp: current_time,
                last_updated: current_time,
            }
        );
        
        // è¨˜éŒ„è¿½è¹¤é–‹å§‹æ™‚é–“
        self.usage_history.push(UsageRecord {
            job_id: "system".to_string(),
            timestamp: current_time,
            tokens_used: 0,
            cost: 0.0,
            operation_type: "tracking_started".to_string(),
            usage_data: UsageData {
                job_id: "system".to_string(),
                session_id: None,
                tokens_input: 0,
                tokens_output: 0,
                tokens_total: 0,
                cost_usd: 0.0,
                cost_total: 0.0,
                model_name: None,
                execution_duration_ms: 0,
                timestamp: current_time,
                last_updated: current_time,
            },
            recorded_at: current_time,
        });
        
        info!("âœ… Usage tracking started successfully");
        Ok(())
    }

    pub async fn stop_tracking(&mut self) -> Result<()> {
        info!("ğŸ“ˆ Stopping usage tracking...");
        // TODO: å¯¦ä½œåœæ­¢é‚è¼¯
        Ok(())
    }
}

/// æŒ‡æ¨™æ•¸å€¼é¡å‹æšèˆ‰
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum MetricValue {
    /// è¨ˆæ•¸å™¨é¡å‹
    Counter(u64),
    /// é‡è¡¨é¡å‹ 
    Gauge(f64),
    /// æ™‚é–“æˆ³é¡å‹
    Timestamp(DateTime<Utc>),
    /// ç›´æ–¹åœ–é¡å‹
    Histogram(f64),
}

#[derive(Debug, Clone)]
pub struct HistoricalMetric {
    pub name: String,
    pub value: f64,
    pub timestamp: DateTime<Utc>,
}

#[derive(Debug, Clone)]
pub struct AlertConfig {
    pub name: String,
    pub threshold: f64,
    pub condition: String,
}

#[derive(Debug)]
pub struct CostCalculator {
    // TODO: å¯¦ä½œæˆæœ¬è¨ˆç®—é‚è¼¯
}

impl CostCalculator {
    pub fn new() -> Self {
        Self {}
    }
}

#[derive(Debug, Clone)]
pub struct UsageRecord {
    pub job_id: String,
    pub timestamp: DateTime<Utc>,
    pub tokens_used: u64,
    pub cost: f64,
    pub operation_type: String,
    pub usage_data: UsageData,
    pub recorded_at: DateTime<Utc>,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_unified_scheduler_creation() {
        let scheduler = UnifiedScheduler::new().await;
        assert!(scheduler.is_ok());
    }

    #[tokio::test]
    async fn test_task_hierarchy() {
        let mut hierarchy = TaskHierarchy::default();

        // æ¸¬è©¦æ·»åŠ é—œä¿‚
        let result = hierarchy.add_relationship("parent1".to_string(), "child1".to_string());
        assert!(result.is_ok());

        // æ¸¬è©¦ç²å–å­ä»»å‹™
        let children = hierarchy.get_children("parent1");
        assert_eq!(children.len(), 1);
        assert_eq!(children[0], "child1");

        // æ¸¬è©¦å¾ªç’°ä¾è³´æª¢æŸ¥
        let cycle_result = hierarchy.add_relationship("child1".to_string(), "parent1".to_string());
        assert!(cycle_result.is_err());
    }
}
